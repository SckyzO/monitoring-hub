{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Monitoring Hub","text":"<p>The definitive Software Factory for Prometheus Exporters.</p> <p> </p>"},{"location":"#project-goal","title":"\ud83c\udfaf Project Goal","text":"<p>Monitoring Hub is an automated Software Factory that transforms simple YAML manifests into production-ready monitoring tools. It focuses on Enterprise Standards, Multi-Architecture support, and Full Automation.</p>"},{"location":"#key-features","title":"\ud83d\ude80 Key Features","text":"<ul> <li>Native Multi-Arch: Every tool is built for <code>x86_64</code> and <code>aarch64</code> (ARM64)</li> <li>Hardened Security: All Docker images use Red Hat UBI 9 Minimal</li> <li>Linux Standard (FHS): RPMs include system users, standard paths, and systemd integration</li> <li>Zero-Click Updates: Automated watcher opens PRs and merges when tests pass</li> <li>Always Up-to-Date: Never worry about upstream releases again</li> </ul>"},{"location":"#whats-included","title":"\ud83d\udce6 What's Included","text":"<p>The factory currently builds and maintains 30+ Prometheus exporters, including:</p> <ul> <li>System Monitoring: node_exporter, process_exporter, systemd_exporter</li> <li>Database: postgres_exporter, mysql_exporter, mongodb_exporter, redis_exporter</li> <li>Web Services: nginx_exporter, apache_exporter, blackbox_exporter</li> <li>Storage: ceph_exporter, ipmi_exporter, smartctl_exporter</li> <li>Messaging: kafka_exporter, rabbitmq_exporter, nats_exporter</li> <li>And many more...</li> </ul> <p>Browse the complete catalog \u2192</p>"},{"location":"#quick-links","title":"\ud83d\udcda Quick Links","text":"<ul> <li> <p> Quick Start</p> <p>Get up and running in minutes</p> </li> <li> <p> User Guide</p> <p>Learn how to add new exporters</p> </li> <li> <p> Architecture</p> <p>Understand how it works</p> </li> <li> <p> API Reference</p> <p>Explore the codebase</p> </li> </ul>"},{"location":"#how-it-works","title":"\ud83c\udfed How It Works","text":"<pre><code>graph LR\n    A[YAML Manifest] --&gt; B[Builder]\n    B --&gt; C[RPM Packages]\n    B --&gt; D[Docker Images]\n    C --&gt; E[YUM Repository]\n    D --&gt; F[GHCR Registry]\n    E --&gt; G[Production]\n    F --&gt; G</code></pre> <ol> <li>Define: Create a simple YAML manifest describing the exporter</li> <li>Build: Automated CI builds RPM and Docker artifacts</li> <li>Distribute: Packages are published to YUM repo and GHCR</li> <li>Update: Watcher monitors upstream and auto-updates</li> </ol>"},{"location":"#distribution","title":"\ud83d\udccb Distribution","text":""},{"location":"#yum-repository-rpm","title":"YUM Repository (RPM)","text":"<pre><code># Configure repository\nsudo dnf config-manager --add-repo https://sckyzo.github.io/monitoring-hub/el9/$(arch)/\n\n# Install any exporter\nsudo dnf install node_exporter\n\n# Enable and start\nsudo systemctl enable --now node_exporter\n</code></pre>"},{"location":"#container-registry-docker","title":"Container Registry (Docker)","text":"<pre><code># Pull any exporter\ndocker pull ghcr.io/sckyzo/monitoring-hub/node_exporter:latest\n\n# Run\ndocker run -d -p 9100:9100 ghcr.io/sckyzo/monitoring-hub/node_exporter:latest\n</code></pre>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>We welcome contributions! Check out our Contributing Guide to get started.</p>"},{"location":"#license","title":"\ud83d\udcc4 License","text":"<p>Distributed under the MIT License. See LICENSE for more information.</p>"},{"location":"api-reference/builder/","title":"Builder API","text":""},{"location":"api-reference/builder/#core.engine.builder","title":"<code>core.engine.builder</code>","text":""},{"location":"api-reference/builder/#core.engine.builder-functions","title":"Functions","text":""},{"location":"api-reference/builder/#core.engine.builder.copy_local_binary","title":"<code>copy_local_binary(data, output_dir, manifest_dir)</code>","text":"<p>Copy local binary or archive to output directory. Mirrors the \"Smart Copy Logic\" pattern used for extra_files.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>Manifest data</p> required <code>output_dir</code> <p>Build output directory</p> required <code>manifest_dir</code> <p>Directory containing the manifest (for relative paths)</p> required Source code in <code>core/engine/builder.py</code> <pre><code>def copy_local_binary(data, output_dir, manifest_dir):\n    \"\"\"\n    Copy local binary or archive to output directory.\n    Mirrors the \"Smart Copy Logic\" pattern used for extra_files.\n\n    Args:\n        data: Manifest data\n        output_dir: Build output directory\n        manifest_dir: Directory containing the manifest (for relative paths)\n    \"\"\"\n    binary_name = data[\"build\"][\"binary_name\"]\n    local_binary = data[\"upstream\"].get(\"local_binary\")\n    local_archive = data[\"upstream\"].get(\"local_archive\")\n    binaries_to_find = [binary_name] + data[\"build\"].get(\"extra_binaries\", [])\n    found_binaries = []\n\n    if local_binary:\n        # Case 1: Direct binary file\n        source_path = os.path.join(manifest_dir, local_binary)\n\n        if not os.path.exists(source_path):\n            click.echo(f\"Error: Local binary not found: {source_path}\", err=True)\n            raise click.Abort()\n\n        if not os.path.isfile(source_path):\n            click.echo(f\"Error: Path is not a file: {source_path}\", err=True)\n            raise click.Abort()\n\n        click.echo(f\"Copying local binary: {source_path}\")\n        dest_path = os.path.join(output_dir, binary_name)\n        shutil.copy(source_path, dest_path)\n        os.chmod(dest_path, 0o755)  # nosec B103 - Executable binary requires execute permissions\n        found_binaries.append(binary_name)\n        click.echo(f\"Binary ready: {dest_path}\")\n\n    elif local_archive:\n        # Case 2: Archive (.tar.gz or .gz)\n        source_path = os.path.join(manifest_dir, local_archive)\n\n        if not os.path.exists(source_path):\n            click.echo(f\"Error: Local archive not found: {source_path}\", err=True)\n            raise click.Abort()\n\n        click.echo(f\"Extracting local archive: {source_path}\")\n\n        if source_path.endswith(\".gz\") and not source_path.endswith(\".tar.gz\"):\n            # Simple .gz file (single binary)\n            click.echo(\"Decompressing single binary...\")\n            final_path = os.path.join(output_dir, binary_name)\n            with gzip.open(source_path, \"rb\") as f_in, open(final_path, \"wb\") as f_out:\n                shutil.copyfileobj(f_in, f_out)\n            os.chmod(final_path, 0o755)  # nosec B103 - Executable binary requires execute permissions\n            found_binaries.append(binary_name)\n            click.echo(f\"Binary ready: {final_path}\")\n\n        elif source_path.endswith(\".tar.gz\"):\n            # .tar.gz archive - reuse existing logic from download_and_extract\n            click.echo(f\"Extracting binaries {binaries_to_find}...\")\n            extracted_dirs = set()\n            with tarfile.open(source_path, \"r:gz\") as tar:\n                members = tar.getmembers()\n                for b_name in binaries_to_find:\n                    member_to_extract = None\n                    for member in members:\n                        if member.name.endswith(f\"/{b_name}\") or member.name == b_name:\n                            member_to_extract = member\n                            break\n\n                    if member_to_extract:\n                        tar.extract(member_to_extract, path=output_dir)\n                        extracted_path = os.path.join(\n                            output_dir, member_to_extract.name\n                        )\n                        final_path = os.path.join(output_dir, b_name)\n\n                        if extracted_path != final_path:\n                            shutil.move(extracted_path, final_path)\n\n                        parts = member_to_extract.name.split(\"/\")\n                        if len(parts) &gt; 1:\n                            extracted_dirs.add(parts[0])\n\n                        os.chmod(final_path, 0o755)  # nosec B103 - Executable binary requires execute permissions\n                        found_binaries.append(b_name)\n                        click.echo(f\"Binary ready: {final_path}\")\n                    else:\n                        click.echo(f\"Warning: Binary '{b_name}' not found in archive.\")\n\n            # Cleanup extracted directories\n            for d in extracted_dirs:\n                dir_to_remove = os.path.join(output_dir, d)\n                if os.path.isdir(dir_to_remove):\n                    shutil.rmtree(dir_to_remove, ignore_errors=True)\n        else:\n            click.echo(f\"Error: Unsupported archive format: {source_path}\", err=True)\n            raise click.Abort()\n\n    if not found_binaries:\n        click.echo(\"Error: No binaries found.\", err=True)\n        raise click.Abort()\n</code></pre>"},{"location":"api-reference/builder/#core.engine.builder.download_and_extract","title":"<code>download_and_extract(data, output_dir, arch)</code>","text":"<p>Downloads the upstream binary release and extracts it.</p> <p>This function handles the complexity of GitHub release naming conventions: 1. Some projects use 'v' prefixes in tags but not in filenames. 2. Some projects use dashes, others dots. 3. We support custom 'archive_name' patterns to handle any edge case. 4. Supports .tar.gz archives and simple .gz compressed binaries.</p> Source code in <code>core/engine/builder.py</code> <pre><code>@retry(\n    stop=stop_after_attempt(3),\n    wait=wait_exponential(multiplier=1, min=2, max=10),\n    retry=retry_if_exception_type((requests.exceptions.RequestException, OSError)),\n    reraise=True,\n)\ndef download_and_extract(data, output_dir, arch):\n    \"\"\"\n    Downloads the upstream binary release and extracts it.\n\n    This function handles the complexity of GitHub release naming conventions:\n    1. Some projects use 'v' prefixes in tags but not in filenames.\n    2. Some projects use dashes, others dots.\n    3. We support custom 'archive_name' patterns to handle any edge case.\n    4. Supports .tar.gz archives and simple .gz compressed binaries.\n    \"\"\"\n    name = data[\"name\"]\n    version = data[\"version\"]\n    repo = data[\"upstream\"][\"repo\"]\n    binary_name = data[\"build\"][\"binary_name\"]\n    archive_pattern = data[\"upstream\"].get(\"archive_name\")\n\n    # We strip the 'v' prefix for filename construction because Go projects\n    # typically tag 'v1.0.0' but release 'project-1.0.0.tar.gz'.\n    clean_version = version.lstrip(\"v\") if version.startswith(\"v\") else version\n\n    # Construct the download URL\n    if archive_pattern:\n        # User provided a specific pattern (e.g. for slurm_exporter using dashes)\n        filename = archive_pattern.format(\n            name=name,\n            version=version,\n            clean_version=clean_version,\n            arch=arch,\n            rpm_arch=\"x86_64\" if arch == \"amd64\" else \"aarch64\",\n        )\n    else:\n        # Default standard Prometheus naming convention\n        upstream_arch = f\"linux-{arch}\"\n        filename = f\"{name}-{clean_version}.{upstream_arch}.tar.gz\"\n\n    url = f\"https://github.com/{repo}/releases/download/{version}/{filename}\"\n\n    click.echo(f\"Downloading {url}...\")\n    local_file = os.path.join(output_dir, filename)\n\n    # We look for the main binary AND any extra binaries (like promtool)\n    binaries_to_find = [binary_name] + data[\"build\"].get(\"extra_binaries\", [])\n    found_binaries = []\n\n    try:\n        with requests.get(url, stream=True, timeout=30) as r:\n            r.raise_for_status()\n            with open(local_file, \"wb\") as f:\n                for chunk in r.iter_content(chunk_size=8192):\n                    f.write(chunk)\n\n        # Case 1: Simple .gz file (single binary)\n        if filename.endswith(\".gz\") and not filename.endswith(\".tar.gz\"):\n            click.echo(f\"Decompressing single binary {filename}...\")\n            final_path = os.path.join(output_dir, binary_name)\n            with gzip.open(local_file, \"rb\") as f_in, open(final_path, \"wb\") as f_out:\n                shutil.copyfileobj(f_in, f_out)\n            os.chmod(final_path, 0o755)  # nosec B103 - Executable binary requires execute permissions\n            found_binaries.append(binary_name)\n            click.echo(f\"Binary ready: {final_path}\")\n\n        # Case 2: .tar.gz archive\n        else:\n            click.echo(f\"Extracting binaries {binaries_to_find}...\")\n            # We need to track extracted dirs to clean them up later\n            extracted_dirs = set()\n            with tarfile.open(local_file, \"r:gz\") as tar:\n                members = tar.getmembers()\n                for b_name in binaries_to_find:\n                    member_to_extract = None\n                    # Search for the binary, even if nested in a subfolder\n                    for member in members:\n                        if member.name.endswith(f\"/{b_name}\") or member.name == b_name:\n                            member_to_extract = member\n                            break\n\n                    if member_to_extract:\n                        # Flatten: we extract everything to the root of output_dir\n                        tar.extract(member_to_extract, path=output_dir, filter=\"data\")\n                        extracted_path = os.path.join(\n                            output_dir, member_to_extract.name\n                        )\n                        final_path = os.path.join(output_dir, b_name)\n\n                        if extracted_path != final_path:\n                            shutil.move(extracted_path, final_path)\n\n                        parts = member_to_extract.name.split(\"/\")\n                        if len(parts) &gt; 1:\n                            extracted_dirs.add(parts[0])\n\n                        os.chmod(final_path, 0o755)  # nosec B103 - Executable binary requires execute permissions\n                        found_binaries.append(b_name)\n                        click.echo(f\"Binary ready: {final_path}\")\n                    else:\n                        click.echo(f\"Warning: Binary '{b_name}' not found.\")\n\n            # Clean up the folder structure from the tarball (we keep only binaries)\n            for d in extracted_dirs:\n                dir_to_remove = os.path.join(output_dir, d)\n                if os.path.isdir(dir_to_remove):\n                    shutil.rmtree(dir_to_remove, ignore_errors=True)\n\n        if not found_binaries:\n            click.echo(\"Error: No binaries found in archive.\", err=True)\n            raise click.Abort()\n\n    except Exception as e:\n        click.echo(f\"Failed to process artifact: {e}\", err=True)\n        raise e\n    finally:\n        if os.path.exists(local_file):\n            os.remove(local_file)\n</code></pre>"},{"location":"api-reference/builder/#core.engine.builder.download_extra_sources","title":"<code>download_extra_sources(data, output_dir)</code>","text":"<p>Download additional files (like config examples) that are not in the release tarball.</p> Source code in <code>core/engine/builder.py</code> <pre><code>@retry(\n    stop=stop_after_attempt(3),\n    wait=wait_exponential(multiplier=1, min=2, max=10),\n    retry=retry_if_exception_type(requests.exceptions.RequestException),\n    reraise=True,\n)\ndef download_extra_sources(data, output_dir):\n    \"\"\"\n    Download additional files (like config examples) that are not in the release tarball.\n    \"\"\"\n    extra_sources = data.get(\"build\", {}).get(\"extra_sources\", [])\n    for source in extra_sources:\n        url = source[\"url\"]\n        filename = source[\"filename\"]\n        click.echo(f\"Downloading extra source: {url}...\")\n        try:\n            r = requests.get(url, timeout=30)\n            r.raise_for_status()\n            with open(os.path.join(output_dir, filename), \"wb\") as f:\n                f.write(r.content)\n            click.echo(f\"Extra source saved as {filename}\")\n        except Exception as e:\n            click.echo(f\"Warning: Failed to download extra source {url}: {e}\")\n</code></pre>"},{"location":"api-reference/builder/#core.engine.builder.get_upstream_license","title":"<code>get_upstream_license(repo_slug)</code>","text":"<p>Fetch license information from GitHub API. Returns SPDX ID (e.g. 'MIT', 'Apache-2.0') or None.</p> Source code in <code>core/engine/builder.py</code> <pre><code>def get_upstream_license(repo_slug):\n    \"\"\"\n    Fetch license information from GitHub API.\n    Returns SPDX ID (e.g. 'MIT', 'Apache-2.0') or None.\n    \"\"\"\n    try:\n        token = os.environ.get(\"GITHUB_TOKEN\")\n        headers = {\"Accept\": \"application/vnd.github.v3+json\"}\n        if token:\n            headers[\"Authorization\"] = f\"token {token}\"\n\n        url = f\"https://api.github.com/repos/{repo_slug}/license\"\n        r = requests.get(url, headers=headers, timeout=5)\n        if r.status_code == 200:\n            data = r.json()\n            return data.get(\"license\", {}).get(\"spdx_id\")\n    except Exception as e:\n        click.echo(f\"Warning: Could not fetch license for {repo_slug}: {e}\")\n    return None\n</code></pre>"},{"location":"api-reference/builder/#core.engine.builder.load_manifest","title":"<code>load_manifest(path)</code>","text":"<p>Loads and validates the manifest YAML file against the strict schema. This ensures we fail early if the user input is invalid.</p> Source code in <code>core/engine/builder.py</code> <pre><code>def load_manifest(path):\n    \"\"\"\n    Loads and validates the manifest YAML file against the strict schema.\n    This ensures we fail early if the user input is invalid.\n    \"\"\"\n    with open(path) as f:\n        data = yaml.safe_load(f)\n\n    schema = ManifestSchema()\n    try:\n        return schema.load(data)\n    except ValidationError as err:\n        click.echo(f\"Validation error in {path}: {err.messages}\", err=True)\n        raise click.Abort() from err\n</code></pre>"},{"location":"api-reference/builder/#core.engine.builder.render_deb_templates","title":"<code>render_deb_templates(data, output_dir, arch, env, manifest_dir)</code>","text":"<p>Generate the debian/ directory with all required DEB packaging files: - control (package metadata) - rules (build rules) - changelog (version history) - compat (debhelper compatibility level) - .service (systemd unit if enabled) Source code in <code>core/engine/builder.py</code> <pre><code>def render_deb_templates(data, output_dir, arch, env, manifest_dir):\n    \"\"\"\n    Generate the debian/ directory with all required DEB packaging files:\n    - control (package metadata)\n    - rules (build rules)\n    - changelog (version history)\n    - compat (debhelper compatibility level)\n    - &lt;name&gt;.service (systemd unit if enabled)\n    \"\"\"\n    from datetime import datetime\n\n    debian_dir = os.path.join(output_dir, \"debian\")\n    os.makedirs(debian_dir, exist_ok=True)\n    click.echo(f\"Creating debian/ directory at {debian_dir}\")\n\n    # Add build date for changelog (RFC 2822 format required by Debian)\n    from datetime import timezone\n\n    dt = datetime.now(timezone.utc)\n    data[\"build_date\"] = dt.strftime(\"%a, %d %b %Y %H:%M:%S %z\")\n\n    # Add binary_name to root level for easier access in templates\n    data[\"binary_name\"] = data.get(\"build\", {}).get(\"binary_name\", data[\"name\"])\n\n    # 1. Generate debian/control\n    template = env.get_template(\"debian_control.j2\")\n    control_content = template.render(data)\n    with open(os.path.join(debian_dir, \"control\"), \"w\") as f:\n        f.write(control_content)\n    click.echo(\"  Created debian/control\")\n\n    # 2. Generate debian/rules\n    template = env.get_template(\"debian_rules.j2\")\n    rules_content = template.render(data)\n    rules_path = os.path.join(debian_dir, \"rules\")\n    with open(rules_path, \"w\") as f:\n        f.write(rules_content)\n    os.chmod(rules_path, 0o755)  # nosec B103 - debian/rules must be executable\n    click.echo(\"  Created debian/rules\")\n\n    # 3. Generate debian/changelog\n    template = env.get_template(\"debian_changelog.j2\")\n    changelog_content = template.render(data)\n    with open(os.path.join(debian_dir, \"changelog\"), \"w\") as f:\n        f.write(changelog_content)\n    click.echo(\"  Created debian/changelog\")\n\n    # 4. Create debian/compat (debhelper compatibility level)\n    with open(os.path.join(debian_dir, \"compat\"), \"w\") as f:\n        f.write(\"10\\n\")\n    click.echo(\"  Created debian/compat\")\n\n    # 5. Generate systemd service if enabled\n    if data.get(\"artifacts\", {}).get(\"deb\", {}).get(\"systemd\", {}).get(\"enabled\"):\n        template = env.get_template(\"debian_service.j2\")\n        service_content = template.render(data)\n        # Debian package names use dashes instead of underscores\n        deb_name = data[\"name\"].replace(\"_\", \"-\")\n        service_file = os.path.join(debian_dir, f\"{deb_name}.service\")\n        with open(service_file, \"w\") as f:\n            f.write(service_content)\n        click.echo(f\"  Created debian/{deb_name}.service\")\n\n    # 6. Handle extra files (copy to debian/ for rules to reference)\n    artifacts = data.get(\"artifacts\", {})\n    deb_config = artifacts.get(\"deb\", {})\n    for extra_file in deb_config.get(\"extra_files\", []):\n        source_path = extra_file[\"source\"]\n        local_src = os.path.join(manifest_dir, source_path)\n        downloaded_src = os.path.join(output_dir, source_path)\n\n        dst_name = os.path.basename(source_path)\n        dst_path = os.path.join(output_dir, dst_name)\n\n        if os.path.exists(local_src):\n            shutil.copy(local_src, dst_path)\n            click.echo(f\"  Copied extra file: {dst_name}\")\n        elif os.path.exists(downloaded_src):\n            if downloaded_src != dst_path:\n                shutil.copy(downloaded_src, dst_path)\n                click.echo(f\"  Copied extra file: {dst_name}\")\n        else:\n            click.echo(f\"  Warning: Extra file {source_path} not found\")\n\n        extra_file[\"build_source\"] = dst_name\n\n    click.echo(\"\u2713 DEB packaging files generated successfully\")\n</code></pre>"},{"location":"api-reference/schema/","title":"Schema API","text":""},{"location":"api-reference/schema/#core.engine.schema","title":"<code>core.engine.schema</code>","text":""},{"location":"api-reference/schema/#core.engine.schema-classes","title":"Classes","text":""},{"location":"api-reference/schema/#core.engine.schema.UpstreamSchema","title":"<code>UpstreamSchema</code>","text":"<p>               Bases: <code>Schema</code></p>"},{"location":"api-reference/schema/#core.engine.schema.UpstreamSchema-functions","title":"Functions","text":""},{"location":"api-reference/schema/#core.engine.schema.UpstreamSchema.validate_upstream","title":"<code>validate_upstream(data, **_kwargs)</code>","text":"<p>Validate type-specific requirements.</p> Source code in <code>core/engine/schema.py</code> <pre><code>@validates_schema\ndef validate_upstream(self, data, **_kwargs):\n    \"\"\"Validate type-specific requirements.\"\"\"\n    if data.get(\"type\") == \"github\":\n        if not data.get(\"repo\"):\n            raise ValidationError(\"'repo' is required for upstream type 'github'\")\n    elif data.get(\"type\") == \"local\":\n        if not data.get(\"local_binary\") and not data.get(\"local_archive\"):\n            raise ValidationError(\n                \"'local_binary' or 'local_archive' required for upstream type 'local'\"\n            )\n        if data.get(\"local_binary\") and data.get(\"local_archive\"):\n            raise ValidationError(\n                \"Only one of 'local_binary' or 'local_archive' allowed\"\n            )\n</code></pre>"},{"location":"api-reference/state-manager/","title":"State Manager API","text":""},{"location":"api-reference/state-manager/#core.engine.state_manager","title":"<code>core.engine.state_manager</code>","text":""},{"location":"api-reference/state-manager/#core.engine.state_manager-functions","title":"Functions","text":""},{"location":"api-reference/state-manager/#core.engine.state_manager.get_local_state","title":"<code>get_local_state(exporters_dir=EXPORTERS_DIR)</code>","text":"<p>Reads all local manifest.yaml files to build the current desired state.</p> Source code in <code>core/engine/state_manager.py</code> <pre><code>def get_local_state(exporters_dir=EXPORTERS_DIR):\n    \"\"\"\n    Reads all local manifest.yaml files to build the current desired state.\n    \"\"\"\n    local_state = {}\n    if not os.path.isdir(exporters_dir):\n        return {}\n\n    for exporter_name in os.listdir(exporters_dir):\n        manifest_path = os.path.join(exporters_dir, exporter_name, \"manifest.yaml\")\n        if os.path.exists(manifest_path):\n            try:\n                with open(manifest_path) as f:\n                    data = yaml.safe_load(f)\n                    # Normalize version (strip 'v' prefix if present to match catalog standard)\n                    version = data[\"version\"].lstrip(\"v\")\n                    local_state[exporter_name] = version\n            except Exception as e:\n                print(f\"Error reading {manifest_path}: {e}\", file=sys.stderr)\n    return local_state\n</code></pre>"},{"location":"api-reference/state-manager/#core.engine.state_manager.get_remote_catalog","title":"<code>get_remote_catalog(catalog_url=DEFAULT_CATALOG_URL)</code>","text":"<p>Fetches the current state of the repository from the deployed catalog.json. Returns a dictionary keyed by exporter name with version info.</p> Source code in <code>core/engine/state_manager.py</code> <pre><code>@retry(\n    stop=stop_after_attempt(3),\n    wait=wait_exponential(multiplier=1, min=2, max=10),\n    retry=retry_if_exception_type(requests.exceptions.RequestException),\n    reraise=True,\n)\ndef get_remote_catalog(catalog_url=DEFAULT_CATALOG_URL):\n    \"\"\"\n    Fetches the current state of the repository from the deployed catalog.json.\n    Returns a dictionary keyed by exporter name with version info.\n    \"\"\"\n    try:\n        print(f\"Fetching remote catalog from {catalog_url}...\", file=sys.stderr)\n        r = requests.get(catalog_url, timeout=10)\n        if r.status_code == 200:\n            data = r.json()\n            # Convert list to dict for easier lookup: {'node_exporter': '1.8.1', ...}\n            return {item[\"name\"]: item[\"version\"] for item in data.get(\"exporters\", [])}\n        else:\n            print(\n                f\"Warning: Remote catalog not found (Status {r.status_code}). Assuming empty state.\",\n                file=sys.stderr,\n            )\n            return {}\n    except Exception as e:\n        print(\n            f\"Warning: Could not fetch remote catalog: {e}. Assuming empty state.\",\n            file=sys.stderr,\n        )\n        return {}\n</code></pre>"},{"location":"architecture/build-pipeline/","title":"Build Pipeline","text":"<p>Detailed documentation of the build pipeline.</p>"},{"location":"architecture/build-pipeline/#pipeline-stages","title":"Pipeline Stages","text":""},{"location":"architecture/build-pipeline/#1-state-management","title":"1. State Management","text":"<p>Compares local manifests against deployed catalog.json to determine what needs rebuilding.</p>"},{"location":"architecture/build-pipeline/#2-artifact-generation","title":"2. Artifact Generation","text":"<p>Builder downloads upstream binaries, extracts them, and renders Jinja2 templates.</p>"},{"location":"architecture/build-pipeline/#3-parallel-builds","title":"3. Parallel Builds","text":"<ul> <li>RPM: Built for el8, el9, el10 \u00d7 amd64, arm64</li> <li>Docker: Built as multi-arch images</li> </ul>"},{"location":"architecture/build-pipeline/#4-validation","title":"4. Validation","text":"<ul> <li>Port checks for Docker containers</li> <li>Command validation for binaries</li> <li>Schema validation for manifests</li> </ul>"},{"location":"architecture/build-pipeline/#5-publication","title":"5. Publication","text":"<ul> <li>RPMs pushed to GitHub Pages YUM repository</li> <li>Docker images pushed to GHCR</li> <li>Catalog updated</li> </ul>"},{"location":"architecture/build-pipeline/#incremental-builds","title":"Incremental Builds","text":"<p>Only changed exporters are rebuilt, saving time and resources.</p>"},{"location":"architecture/ci-cd/","title":"CI/CD Workflows","text":"<p>GitHub Actions workflows that power the factory.</p>"},{"location":"architecture/ci-cd/#main-workflows","title":"Main Workflows","text":""},{"location":"architecture/ci-cd/#releaseyml","title":"release.yml","text":"<p>Main build pipeline triggered on push to main or manual dispatch.</p>"},{"location":"architecture/ci-cd/#scan-updatesyml","title":"scan-updates.yml","text":"<p>Automated watcher that checks upstream for new versions.</p>"},{"location":"architecture/ci-cd/#build-pryml","title":"build-pr.yml","text":"<p>PR validation that builds only changed exporters.</p>"},{"location":"architecture/ci-cd/#update-siteyml","title":"update-site.yml","text":"<p>Portal regeneration when catalog changes.</p>"},{"location":"architecture/ci-cd/#securityyml","title":"security.yml","text":"<p>Security scanning workflow that runs on pull requests and pushes to main.</p> <p>Scanners: - Bandit: Python code security issues (SQL injection, hardcoded secrets, insecure functions) - pip-audit: Dependency vulnerability scanning (CVE database) - Trivy: Container image vulnerability scanning with SARIF upload</p> <p>Integration: - Uploads SARIF reports to GitHub Security tab - Requires <code>security-events: write</code> permission - Integrates with GitHub Advanced Security - Fails CI on critical vulnerabilities</p> <p>View Results: Navigate to Security \u2192 Code scanning alerts in GitHub to view Trivy vulnerability reports.</p>"},{"location":"architecture/ci-cd/#workflow-features","title":"Workflow Features","text":"<ul> <li>Parallel matrix builds</li> <li>Incremental builds</li> <li>Automatic deployment</li> <li>Validation tests</li> <li>Security scanning with SARIF integration</li> <li>Multi-architecture support (amd64, arm64)</li> </ul>"},{"location":"architecture/overview/","title":"Architecture Overview","text":"<p>Monitoring Hub is built as a Software Factory with automated build pipelines.</p>"},{"location":"architecture/overview/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph TD\n    A[YAML Manifests] --&gt; B[State Manager]\n    B --&gt; C{Changed?}\n    C --&gt;|Yes| D[Builder]\n    C --&gt;|No| E[Skip]\n    D --&gt; F[RPM Builder]\n    D --&gt; G[Docker Builder]\n    F --&gt; H[YUM Repo]\n    G --&gt; I[GHCR]\n    J[Watcher] --&gt;|New Version| K[PR]\n    K --&gt;|CI Pass| L[Auto-merge]</code></pre>"},{"location":"architecture/overview/#core-components","title":"Core Components","text":"<ul> <li>Builder (<code>core/engine/builder.py</code>): Downloads binaries and generates build artifacts</li> <li>Schema (<code>core/engine/schema.py</code>): Validates manifest YAML files</li> <li>State Manager (<code>core/engine/state_manager.py</code>): Tracks changes and triggers rebuilds</li> <li>Site Generator (<code>core/engine/site_generator.py</code>): Generates the portal</li> <li>Watcher (<code>core/engine/watcher.py</code>): Monitors upstream for updates</li> </ul>"},{"location":"architecture/overview/#build-flow","title":"Build Flow","text":"<ol> <li>Discovery: State Manager compares local manifests with deployed catalog</li> <li>Generation: Builder downloads binaries and renders templates</li> <li>Build: CI builds RPM and Docker artifacts in parallel</li> <li>Validation: Tests ensure packages work correctly</li> <li>Distribution: Artifacts published to YUM repo and GHCR</li> </ol> <p>See Build Pipeline for details.</p>"},{"location":"architecture/state-management/","title":"State Management","text":"<p>How Monitoring Hub tracks and manages exporter versions.</p>"},{"location":"architecture/state-management/#catalog-system","title":"Catalog System","text":"<p>The <code>catalog.json</code> file contains all deployed exporters and their versions.</p>"},{"location":"architecture/state-management/#change-detection","title":"Change Detection","text":"<p>State Manager compares:</p> <ul> <li>Local manifest versions</li> <li>Deployed catalog versions</li> <li>Force rebuild flags</li> </ul>"},{"location":"architecture/state-management/#version-comparison","title":"Version Comparison","text":"<p>Version format handling:</p> <ul> <li>Strips <code>v</code> prefix for comparison</li> <li>Supports semantic versioning</li> <li>Handles custom version schemes</li> </ul>"},{"location":"contributing/development/","title":"Development Setup","text":"<p>Get your development environment ready using our Docker-first workflow.</p>"},{"location":"contributing/development/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker - The only requirement!</li> <li>Git - For version control</li> </ul> <p>Optional: - Python 3.9+ (only for local development without Docker)</p>"},{"location":"contributing/development/#quick-start-recommended","title":"Quick Start (Recommended)","text":"<p>The simplest way to start is with our <code>./devctl</code> CLI:</p> <pre><code># Clone repository\ngit clone https://github.com/SckyzO/monitoring-hub.git\ncd monitoring-hub\ngit checkout -b feature/my-feature\n\n# Build development Docker image\n./devctl build\n\n# Open interactive shell\n./devctl shell\n\n# Run tests\n./devctl test\n\n# Run linter\n./devctl lint\n</code></pre> <p>That's it! No Python installation needed.</p>"},{"location":"contributing/development/#alternative-local-python-setup","title":"Alternative: Local Python Setup","text":"<p>If you prefer developing without Docker:</p> <pre><code># Create virtual environment\npython -m venv .venv\nsource .venv/bin/activate\n\n# Install dependencies\nmake install\n\n# This installs:\n# - requirements/base.txt (engine dependencies)\n# - requirements/dev.txt (ruff, pytest, mypy)\n# - requirements/docs.txt (mkdocs)\n# - pre-commit hooks\n</code></pre>"},{"location":"contributing/development/#development-workflow","title":"Development Workflow","text":""},{"location":"contributing/development/#using-devctl-recommended","title":"Using devctl (Recommended)","text":"<p>All development tasks are available through <code>./devctl</code>:</p> <pre><code># Code quality\n./devctl test              # Run tests\n./devctl test-cov          # Run tests with coverage\n./devctl lint              # Check Python linting\n./devctl lint-css          # Check CSS linting\n./devctl lint-fix          # Auto-fix linting issues\n./devctl format            # Format code\n./devctl type-check        # Run type checker\n./devctl ci                # Run all CI checks\n\n# Working with exporters\n./devctl create-exporter           # Create new exporter\n./devctl list-exporters            # List all exporters\n./devctl build-exporter &lt;name&gt;     # Build specific exporter\n./devctl test-exporter &lt;name&gt;      # Test build exporter\n\n# Documentation\n./devctl generate-portal   # Generate web portal\n./devctl docs-build        # Build MkDocs docs\n./devctl docs-serve        # Serve docs at localhost:8000\n\n# Utilities\n./devctl shell             # Open interactive shell\n./devctl python &lt;cmd&gt;      # Run Python command\n./devctl help              # Show all commands\n</code></pre>"},{"location":"contributing/development/#using-make","title":"Using Make","text":"<p>For convenience, most <code>devctl</code> commands are aliased in the Makefile:</p> <pre><code>make test              # Same as ./devctl test\nmake lint              # Same as ./devctl lint\nmake format            # Same as ./devctl format\nmake ci                # Same as ./devctl ci\n</code></pre>"},{"location":"contributing/development/#local-python-workflow-advanced","title":"Local Python Workflow (Advanced)","text":"<p>If you have Python installed locally and want faster iteration:</p> <pre><code>make local-test        # Run tests locally\nmake local-lint        # Check linting locally\nmake local-format      # Format code locally\nmake pre-commit        # Run pre-commit hooks\n</code></pre> <p>Note: Local commands require <code>make install</code> first to set up the virtual environment.</p>"},{"location":"contributing/development/#testing-exporters-locally","title":"Testing Exporters Locally","text":""},{"location":"contributing/development/#quick-test","title":"Quick Test","text":"<pre><code># Test build an exporter (RPM + Docker + validation)\n./devctl test-exporter node_exporter\n\n# With specific options\n./devctl test-exporter node_exporter --arch arm64 --el10\n</code></pre>"},{"location":"contributing/development/#build-artifacts-only","title":"Build Artifacts Only","text":"<pre><code># Build just the artifacts (no RPM/Docker)\n./devctl build-exporter node_exporter\n\n# Output will be in: build/node_exporter/\n</code></pre>"},{"location":"contributing/development/#validate-manifest","title":"Validate Manifest","text":"<pre><code># Open shell and validate manifest\n./devctl shell\n\n# Inside container:\npython3 -m core.engine.builder \\\n  --manifest exporters/my_exporter/manifest.yaml \\\n  --arch amd64 \\\n  --output-dir /tmp/test\n</code></pre> <p>See Testing Guide for more details.</p>"},{"location":"contributing/pull-requests/","title":"Pull Requests","text":"<p>Guidelines for submitting pull requests.</p>"},{"location":"contributing/pull-requests/#before-you-submit","title":"Before You Submit","text":"<ol> <li>\u2705 Tests pass locally (<code>make test</code>)</li> <li>\u2705 Linting passes (<code>make lint</code>)</li> <li>\u2705 Documentation updated</li> <li>\u2705 Commit messages follow conventions</li> </ol>"},{"location":"contributing/pull-requests/#pr-process","title":"PR Process","text":"<ol> <li>Create Branch: <code>git checkout -b feature/my-feature</code></li> <li>Make Changes: Follow coding standards</li> <li>Test Locally: Run test suite</li> <li>Commit: Use conventional commits</li> <li>Push: <code>git push origin feature/my-feature</code></li> <li>Create PR: On GitHub</li> </ol>"},{"location":"contributing/pull-requests/#pr-template","title":"PR Template","text":"<pre><code>## Description\nBrief description of changes\n\n## Type of Change\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Breaking change\n- [ ] Documentation update\n\n## Testing\n- [ ] Tests pass locally\n- [ ] New tests added\n- [ ] Manual testing completed\n\n## Checklist\n- [ ] Code follows style guidelines\n- [ ] Documentation updated\n- [ ] No breaking changes (or documented)\n</code></pre>"},{"location":"contributing/pull-requests/#ci-checks","title":"CI Checks","text":"<p>All PRs must pass:</p> <ul> <li>\u2705 Linting (ruff)</li> <li>\u2705 Tests (pytest)</li> <li>\u2705 Build validation</li> <li>\u2705 Manifest validation</li> </ul>"},{"location":"contributing/pull-requests/#review-process","title":"Review Process","text":"<p>Maintainers will review and may request changes. Once approved, PRs are merged automatically.</p>"},{"location":"contributing/security/","title":"Security Guidelines","text":"<p>Security best practices for contributing to Monitoring Hub.</p>"},{"location":"contributing/security/#code-security-principles","title":"Code Security Principles","text":""},{"location":"contributing/security/#input-validation","title":"Input Validation","text":"<p>Always validate external input:</p> <pre><code># Good: Strict schema validation\nfrom core.engine.schema import ManifestSchema\nschema = ManifestSchema()\nvalidated_data = schema.load(user_input)\n\n# Bad: Trusting user input\ndata = yaml.safe_load(untrusted_file)  # No validation\n</code></pre> <p>Manifest validation prevents: - Injection attacks through malformed YAML - Unexpected data types causing runtime errors - Missing required fields</p>"},{"location":"contributing/security/#network-operations","title":"Network Operations","text":"<p>Always use timeouts:</p> <pre><code># Good: Timeout prevents hanging\nresponse = requests.get(url, timeout=30)\n\n# Bad: No timeout\nresponse = requests.get(url)  # Can hang indefinitely\n</code></pre> <p>Implement retry logic with exponential backoff:</p> <pre><code>from tenacity import retry, stop_after_attempt, wait_exponential\n\n@retry(\n    stop=stop_after_attempt(3),\n    wait=wait_exponential(multiplier=1, min=2, max=10)\n)\ndef download_file(url):\n    response = requests.get(url, timeout=30)\n    response.raise_for_status()\n    return response.content\n</code></pre>"},{"location":"contributing/security/#template-security","title":"Template Security","text":"<p>Enable Jinja2 autoescape:</p> <pre><code># Good: Autoescape prevents XSS\nfrom jinja2 import Environment, FileSystemLoader, select_autoescape\n\nenv = Environment(\n    loader=FileSystemLoader(template_dir),\n    autoescape=select_autoescape(['html', 'xml', 'j2'])\n)\n\n# Bad: No autoescape\nenv = Environment(loader=FileSystemLoader(template_dir))\n</code></pre>"},{"location":"contributing/security/#exception-handling","title":"Exception Handling","text":"<p>Always chain exceptions for better debugging:</p> <pre><code># Good: Exception chaining preserves context\ntry:\n    dangerous_operation()\nexcept SpecificError as err:\n    logger.error(f\"Operation failed: {err}\")\n    raise click.Abort() from err\n\n# Bad: Losing exception context\nexcept:\n    raise click.Abort()\n</code></pre> <p>Avoid bare except clauses:</p> <pre><code># Good: Specific exception handling\ntry:\n    risky_operation()\nexcept (ValueError, KeyError) as err:\n    handle_error(err)\n\n# Bad: Catches everything including KeyboardInterrupt\ntry:\n    risky_operation()\nexcept:\n    pass\n</code></pre>"},{"location":"contributing/security/#dependency-security","title":"Dependency Security","text":""},{"location":"contributing/security/#managing-dependencies","title":"Managing Dependencies","text":"<ul> <li>Pin versions: Use exact versions in <code>requirements.txt</code></li> <li>Regular updates: Review Dependabot PRs weekly</li> <li>Vulnerability scanning: Check <code>pip-audit</code> reports</li> <li>Minimal dependencies: Only add necessary packages</li> </ul>"},{"location":"contributing/security/#before-adding-dependencies","title":"Before Adding Dependencies","text":"<ol> <li>Check package reputation (GitHub stars, downloads, maintainers)</li> <li>Review security advisories on PyPI Advisory Database</li> <li>Verify package signatures when available</li> <li>Check for known vulnerabilities with <code>pip-audit</code></li> </ol>"},{"location":"contributing/security/#container-security","title":"Container Security","text":""},{"location":"contributing/security/#dockerfile-best-practices","title":"Dockerfile Best Practices","text":"<pre><code># Use minimal base images\nFROM registry.access.redhat.com/ubi9/ubi-minimal\n\n# Run as non-root user\nRUN useradd -r -u 1000 exporter\nUSER exporter\n\n# Use read-only root filesystem\nVOLUME [\"/var/lib/exporter\"]\n</code></pre>"},{"location":"contributing/security/#image-scanning","title":"Image Scanning","text":"<p>Before pushing images:</p> <pre><code># Scan with Trivy\ntrivy image monitoring-hub/exporter:latest\n\n# Check for high/critical vulnerabilities\ntrivy image --severity HIGH,CRITICAL monitoring-hub/exporter:latest\n</code></pre>"},{"location":"contributing/security/#secret-management","title":"Secret Management","text":"<p>Never commit secrets:</p> <ul> <li>API tokens</li> <li>Private keys</li> <li>Passwords</li> <li>Connection strings</li> </ul> <p>Use environment variables:</p> <pre><code># Good: From environment\ntoken = os.environ.get('GITHUB_TOKEN')\n\n# Bad: Hardcoded\ntoken = \"ghp_xxxxxxxxxxxx\"\n</code></pre> <p>Add sensitive files to <code>.gitignore</code>:</p> <pre><code>secrets/\n.env\n*.key\n*.pem\ncredentials.json\n</code></pre>"},{"location":"contributing/security/#security-testing","title":"Security Testing","text":""},{"location":"contributing/security/#automated-ci-security-scanning","title":"Automated CI Security Scanning","text":"<p>The <code>security.yml</code> workflow runs on every pull request and push to main:</p> <p>Bandit (Python Security Scanner) - Scans Python code for common security issues - Checks for SQL injection, hardcoded passwords, insecure functions - Reports findings as GitHub annotations</p> <p>pip-audit (Dependency Vulnerability Scanner) - Scans Python dependencies for known CVEs - Checks against the OSV vulnerability database - Fails CI on high/critical vulnerabilities</p> <p>Trivy (Container Security Scanner) - Scans container images for vulnerabilities - Uploads SARIF reports to GitHub Security tab - Requires <code>security-events: write</code> permission - Integrates with GitHub Advanced Security</p> <p>View security findings: - Go to the Security tab in GitHub - Click Code scanning alerts - Review Trivy vulnerability reports</p>"},{"location":"contributing/security/#pre-commit-checks","title":"Pre-Commit Checks","text":"<p>Install pre-commit hooks:</p> <pre><code>make install\n</code></pre> <p>This runs: - <code>bandit</code>: Security vulnerability scanner - <code>ruff</code>: Linting with security rules - <code>mypy</code>: Type checking</p>"},{"location":"contributing/security/#manual-security-checks","title":"Manual Security Checks","text":"<pre><code># Run security scanner\nmake security\n\n# Check for vulnerable dependencies\npip-audit -r requirements/base.txt\n\n# Scan code for secrets\ngitleaks detect --no-git\n\n# Scan container image with Trivy\ntrivy image --severity HIGH,CRITICAL monitoring-hub/exporter:latest\n</code></pre>"},{"location":"contributing/security/#reporting-security-issues","title":"Reporting Security Issues","text":"<p>Do not open public issues for security vulnerabilities.</p> <p>Follow our Security Policy for responsible disclosure.</p>"},{"location":"contributing/security/#security-checklist-for-contributors","title":"Security Checklist for Contributors","text":"<p>Before submitting a PR:</p> <ul> <li> All network calls have timeouts</li> <li> Input validation on external data</li> <li> No hardcoded secrets or credentials</li> <li> Jinja2 templates use autoescape</li> <li> Exceptions are properly chained</li> <li> No bare <code>except:</code> clauses</li> <li> Dependencies are pinned and reviewed</li> <li> Security tests pass (<code>make security</code>)</li> <li> No new Bandit warnings introduced</li> </ul>"},{"location":"contributing/security/#resources","title":"Resources","text":"<ul> <li>OWASP Top 10</li> <li>Python Security Best Practices</li> <li>Bandit Documentation</li> <li>pip-audit</li> </ul>"},{"location":"contributing/security/#questions","title":"Questions?","text":"<p>For security questions or concerns:</p> <ul> <li>Open a GitHub Discussion</li> <li>Contact maintainers privately for sensitive issues</li> <li>See SECURITY.md for vulnerability reporting</li> </ul>"},{"location":"contributing/standards/","title":"Coding Standards","text":"<p>Code quality standards for Monitoring Hub.</p>"},{"location":"contributing/standards/#commit-messages","title":"Commit Messages","text":"<p>Use Conventional Commits format:</p> <ul> <li><code>feat(exporters): add new exporter</code></li> <li><code>fix(builder): correct archive extraction</code></li> <li><code>docs: update installation guide</code></li> <li><code>test: add builder unit tests</code></li> <li><code>chore(deps): update dependencies</code></li> </ul>"},{"location":"contributing/standards/#code-style","title":"Code Style","text":"<ul> <li>Python: Follow PEP 8, enforced by ruff</li> <li>Formatting: Automated with ruff format</li> <li>Type Hints: Encouraged but not required</li> <li>Docstrings: Google style</li> </ul>"},{"location":"contributing/standards/#testing","title":"Testing","text":"<ul> <li>Write tests for new functionality</li> <li>Maintain or improve coverage</li> <li>Use pytest fixtures for common setup</li> </ul>"},{"location":"contributing/standards/#documentation","title":"Documentation","text":"<ul> <li>Update docs for user-facing changes</li> <li>Include code examples</li> <li>Keep manifest.reference.yaml in sync</li> </ul>"},{"location":"contributing/testing/","title":"Testing Guide","text":"<p>How to write and run tests for Monitoring Hub.</p>"},{"location":"contributing/testing/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\nmake test\n\n# Run with coverage\nmake test-cov\n\n# Run specific test file\npytest core/tests/test_builder.py\n\n# Run specific test\npytest core/tests/test_builder.py::test_load_valid_manifest\n</code></pre>"},{"location":"contributing/testing/#writing-tests","title":"Writing Tests","text":""},{"location":"contributing/testing/#unit-tests","title":"Unit Tests","text":"<pre><code>def test_my_function():\n    result = my_function(\"input\")\n    assert result == \"expected\"\n</code></pre>"},{"location":"contributing/testing/#using-fixtures","title":"Using Fixtures","text":"<pre><code>def test_with_manifest(sample_manifest):\n    assert sample_manifest['name'] == 'test_exporter'\n</code></pre>"},{"location":"contributing/testing/#test-structure","title":"Test Structure","text":"<ul> <li><code>core/tests/</code> - Test files</li> <li><code>core/tests/fixtures/</code> - Test data</li> <li><code>core/tests/conftest.py</code> - Shared fixtures</li> </ul> <p>See conftest.py for available fixtures.</p>"},{"location":"contributing/testing/#code-quality-checks","title":"Code Quality Checks","text":""},{"location":"contributing/testing/#python-linting","title":"Python Linting","text":"<p>Using <code>ruff</code> for fast linting and formatting:</p> <pre><code># Check linting\nmake lint\n\n# Auto-fix issues\nmake lint-fix\n\n# Format code\nmake format\n\n# Type checking\nmake type-check\n</code></pre>"},{"location":"contributing/testing/#css-linting","title":"CSS Linting","text":"<p>Using <code>stylelint</code> for CSS quality in portal and templates:</p> <pre><code># Check CSS linting\nmake docker-lint-css\n\n# Auto-fix CSS issues\nmake docker-lint-fix\n</code></pre> <p>Configuration files: - <code>.stylelintrc.json</code> - Stylelint rules (standard + order plugin) - <code>.stylelintignore</code> - Ignored files (generated files, external assets)</p> <p>Stylelint validates: - Standalone CSS files - Embedded <code>&lt;style&gt;</code> blocks in Jinja2 templates - Portal CSS (<code>core/templates/index.html.j2</code>)</p>"},{"location":"contributing/testing/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Pre-commit hooks automatically run before each commit:</p> <pre><code># Install hooks\npre-commit install\n\n# Run manually\nmake pre-commit\n\n# Update hook versions\npre-commit autoupdate\n</code></pre> <p>Hooks enforce: - Trailing whitespace removal - YAML validation - Python linting (ruff) - Type checking (mypy) - File size limits</p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Choose your preferred installation method based on your environment.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>For YUM/DNF: Enterprise Linux 8, 9, or 10 (RHEL, AlmaLinux, Rocky Linux)</li> <li>For Docker: Docker or Podman installed</li> <li>Architectures: x86_64 or aarch64 (ARM64)</li> </ul>"},{"location":"getting-started/installation/#yum-repository","title":"YUM Repository","text":""},{"location":"getting-started/installation/#configure-repository","title":"Configure Repository","text":"EL9 (Recommended)EL10EL8 <pre><code>sudo dnf config-manager --add-repo https://sckyzo.github.io/monitoring-hub/el9/$(arch)/\n</code></pre> <pre><code>sudo dnf config-manager --add-repo https://sckyzo.github.io/monitoring-hub/el10/$(arch)/\n</code></pre> <pre><code>sudo dnf config-manager --add-repo https://sckyzo.github.io/monitoring-hub/el8/$(arch)/\n</code></pre>"},{"location":"getting-started/installation/#install-exporter","title":"Install Exporter","text":"<pre><code># Install any exporter\nsudo dnf install node_exporter\n\n# Enable and start service\nsudo systemctl enable --now node_exporter\n\n# Check status\nsudo systemctl status node_exporter\n</code></pre>"},{"location":"getting-started/installation/#list-available-packages","title":"List Available Packages","text":"<pre><code>dnf search monitoring-hub\n# or\ndnf list available | grep exporter\n</code></pre>"},{"location":"getting-started/installation/#docker-podman","title":"Docker / Podman","text":""},{"location":"getting-started/installation/#pull-image","title":"Pull Image","text":"<pre><code># Using Docker\ndocker pull ghcr.io/sckyzo/monitoring-hub/node_exporter:latest\n\n# Using Podman\npodman pull ghcr.io/sckyzo/monitoring-hub/node_exporter:latest\n</code></pre>"},{"location":"getting-started/installation/#run-container","title":"Run Container","text":"<pre><code>docker run -d \\\n  --name node_exporter \\\n  -p 9100:9100 \\\n  --restart unless-stopped \\\n  ghcr.io/sckyzo/monitoring-hub/node_exporter:latest\n</code></pre>"},{"location":"getting-started/installation/#docker-compose","title":"Docker Compose","text":"<pre><code>version: '3.8'\n\nservices:\n  node_exporter:\n    image: ghcr.io/sckyzo/monitoring-hub/node_exporter:latest\n    container_name: node_exporter\n    ports:\n      - \"9100:9100\"\n    restart: unless-stopped\n</code></pre>"},{"location":"getting-started/installation/#verification","title":"Verification","text":"<p>Test that the exporter is running:</p> <pre><code># Check metrics endpoint\ncurl http://localhost:9100/metrics\n\n# Or\nwget -qO- http://localhost:9100/metrics\n</code></pre> <p>You should see Prometheus metrics output.</p>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Guide - Get started with your first exporter</li> <li>User Guide - Learn how to add exporters</li> <li>Troubleshooting - Common issues and solutions</li> </ul>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>Get up and running with Monitoring Hub in just a few minutes.</p>"},{"location":"getting-started/quick-start/#for-users-installing-exporters","title":"For Users (Installing Exporters)","text":""},{"location":"getting-started/quick-start/#1-configure-repository","title":"1. Configure Repository","text":"<pre><code>sudo dnf config-manager --add-repo https://sckyzo.github.io/monitoring-hub/el9/$(arch)/\n</code></pre>"},{"location":"getting-started/quick-start/#2-install-exporter","title":"2. Install Exporter","text":"<pre><code>sudo dnf install node_exporter\n</code></pre>"},{"location":"getting-started/quick-start/#3-start-service","title":"3. Start Service","text":"<pre><code>sudo systemctl enable --now node_exporter\n</code></pre>"},{"location":"getting-started/quick-start/#4-verify","title":"4. Verify","text":"<pre><code>curl http://localhost:9100/metrics\n</code></pre> <p>Done! The exporter is running and exposing metrics.</p>"},{"location":"getting-started/quick-start/#for-contributors-adding-exporters","title":"For Contributors (Adding Exporters)","text":""},{"location":"getting-started/quick-start/#1-clone-repository","title":"1. Clone Repository","text":"<pre><code>git clone https://github.com/SckyzO/monitoring-hub.git\ncd monitoring-hub\n</code></pre>"},{"location":"getting-started/quick-start/#2-build-development-environment","title":"2. Build Development Environment","text":"<p>No Python installation required - just Docker!</p> <pre><code>./devctl build\n</code></pre> <p>This creates a Docker image with all development tools pre-installed.</p>"},{"location":"getting-started/quick-start/#3-create-exporter","title":"3. Create Exporter","text":"<pre><code>./devctl create-exporter\n</code></pre> <p>Follow the interactive prompts:</p> <ul> <li>Name: <code>my_exporter</code></li> <li>Repo: <code>owner/my_exporter</code></li> <li>Category: Select appropriate category</li> <li>Description: Short description</li> </ul>"},{"location":"getting-started/quick-start/#4-test-locally","title":"4. Test Locally","text":"<pre><code>./devctl test-exporter my_exporter\n</code></pre> <p>This will build RPM + Docker image and run validation tests.</p>"},{"location":"getting-started/quick-start/#5-commit-and-push","title":"5. Commit and Push","text":"<pre><code>git checkout -b feature/add-my-exporter\ngit add exporters/my_exporter/\ngit commit -m \"feat(exporters): add my_exporter\"\ngit push origin feature/add-my-exporter\n</code></pre>"},{"location":"getting-started/quick-start/#6-create-pull-request","title":"6. Create Pull Request","text":"<p>Open a PR on GitHub. CI will automatically:</p> <ul> <li>Validate the manifest</li> <li>Build RPM packages</li> <li>Build Docker images</li> <li>Run validation tests</li> </ul> <p>Once approved and merged, your exporter will be automatically deployed!</p>"},{"location":"getting-started/quick-start/#whats-next","title":"What's Next?","text":"<ul> <li>Users: Installation Guide for more installation options</li> <li>Contributors: Adding Exporters for detailed guide</li> <li>Developers: Development Setup for setting up dev environment</li> </ul>"},{"location":"getting-started/requirements/","title":"Requirements","text":""},{"location":"getting-started/requirements/#for-using-exporters","title":"For Using Exporters","text":""},{"location":"getting-started/requirements/#system-requirements","title":"System Requirements","text":"<ul> <li>OS: Enterprise Linux 8, 9, or 10 (RHEL, AlmaLinux, Rocky Linux, CentOS Stream)</li> <li>Architecture: x86_64 or aarch64 (ARM64)</li> <li>Disk Space: ~50MB per exporter</li> <li>Memory: Varies by exporter (typically 10-50MB)</li> </ul>"},{"location":"getting-started/requirements/#runtime-requirements","title":"Runtime Requirements","text":"<ul> <li>systemd: For managing services</li> <li>Network: Internet access for DNF repository (or local mirror)</li> </ul>"},{"location":"getting-started/requirements/#for-development","title":"For Development","text":""},{"location":"getting-started/requirements/#required-software","title":"Required Software","text":"<ul> <li>Python: 3.9 or higher</li> <li>Docker: 20.10+ or Podman 3.0+</li> <li>Git: 2.0+</li> </ul>"},{"location":"getting-started/requirements/#python-dependencies","title":"Python Dependencies","text":"<p>Install via <code>requirements.txt</code>:</p> <pre><code>pip install -r requirements/base.txt\n</code></pre> <p>Dependencies include:</p> <ul> <li><code>PyYAML</code> - YAML parsing</li> <li><code>Jinja2</code> - Template rendering</li> <li><code>marshmallow</code> - Schema validation</li> <li><code>requests</code> - HTTP client</li> <li><code>click</code> - CLI framework</li> </ul>"},{"location":"getting-started/requirements/#development-dependencies","title":"Development Dependencies","text":"<p>For running tests and linting:</p> <pre><code>pip install -r requirements/dev.txt\n</code></pre> <p>Includes:</p> <ul> <li><code>pytest</code> - Testing framework</li> <li><code>ruff</code> - Linting and formatting</li> <li><code>mypy</code> - Type checking</li> <li><code>pre-commit</code> - Git hooks</li> </ul>"},{"location":"getting-started/requirements/#documentation-dependencies","title":"Documentation Dependencies","text":"<p>For building docs locally:</p> <pre><code>pip install -r requirements/docs.txt\n</code></pre>"},{"location":"getting-started/requirements/#for-building-exporters","title":"For Building Exporters","text":""},{"location":"getting-started/requirements/#build-environment","title":"Build Environment","text":"<ul> <li>Docker/Podman: Required for RPM builds</li> <li>rpmbuild: Containerized (no host installation needed)</li> <li>Multi-arch: Requires QEMU for cross-compilation (handled by Docker)</li> </ul>"},{"location":"getting-started/requirements/#disk-space","title":"Disk Space","text":"<ul> <li>Per build: ~500MB temporary space</li> <li>Cache: ~2GB for Docker images</li> </ul>"},{"location":"getting-started/requirements/#network-requirements","title":"Network Requirements","text":""},{"location":"getting-started/requirements/#for-cicd","title":"For CI/CD","text":"<ul> <li>Access to <code>github.com</code> (releases, API)</li> <li>Access to <code>ghcr.io</code> (container registry)</li> <li>Access to GitHub Pages (publishing)</li> </ul>"},{"location":"getting-started/requirements/#for-local-development","title":"For Local Development","text":"<ul> <li>Internet access for downloading upstream binaries</li> <li>Optional: GitHub CLI (<code>gh</code>) for enhanced features</li> </ul>"},{"location":"getting-started/requirements/#optional-tools","title":"Optional Tools","text":"<ul> <li>gh CLI: Enhanced GitHub integration</li> <li>make: For using Makefile commands</li> <li>jq: JSON processing in scripts</li> <li>curl/wget: Testing endpoints</li> </ul>"},{"location":"getting-started/requirements/#browser-requirements-portal","title":"Browser Requirements (Portal)","text":"<ul> <li>Modern browsers: Chrome 90+, Firefox 88+, Safari 14+</li> <li>JavaScript: Required</li> <li>Responsive: Works on mobile devices</li> </ul>"},{"location":"user-guide/adding-exporters/","title":"Adding Exporters","text":"<p>Learn how to add a new Prometheus exporter to the Monitoring Hub.</p>"},{"location":"user-guide/adding-exporters/#overview","title":"Overview","text":"<p>Adding a new exporter is a simple process that takes less than 5 minutes. The factory handles all the complexity of building, packaging, and distributing your exporter.</p>"},{"location":"user-guide/adding-exporters/#step-1-create-exporter-scaffold","title":"Step 1: Create Exporter Scaffold","text":"<p>Use the Docker-first creator tool:</p> <pre><code>./devctl create-exporter\n</code></pre> <p>Or using Make: <pre><code>make create-exporter\n</code></pre></p> <p>You'll be prompted for:</p> <ul> <li>Exporter Name: Technical name (e.g., <code>redis_exporter</code>)</li> <li>GitHub Repository: Upstream repo (e.g., <code>oliver006/redis_exporter</code>)</li> <li>Category: Choose from System, Database, Web, Network, etc.</li> <li>Description: Short one-liner description</li> </ul> <p>The script will automatically:</p> <ul> <li>Fetch latest version from GitHub</li> <li>Detect supported architectures</li> <li>Create <code>exporters/my_exporter/</code> directory</li> <li>Generate <code>manifest.yaml</code> with sensible defaults</li> <li>Create <code>README.md</code> template</li> <li>Create <code>assets/</code> directory for config files</li> </ul> <p>Note: No Python installation required - everything runs in Docker!</p>"},{"location":"user-guide/adding-exporters/#step-2-review-and-customize-manifest","title":"Step 2: Review and Customize Manifest","text":"<p>Open <code>exporters/my_exporter/manifest.yaml</code> and review:</p>"},{"location":"user-guide/adding-exporters/#basic-information","title":"Basic Information","text":"<pre><code>name: my_exporter\ndescription: Exports metrics for My Service\ncategory: Database\nversion: v1.2.3\n# Optional: License will be auto-detected from GitHub if not specified\n# license: Apache-2.0\n</code></pre> <p>License Auto-Detection: The builder automatically queries the GitHub API to detect the upstream project's license (SPDX format). If detection fails or the field is omitted, it defaults to <code>Apache-2.0</code>. Common values include: - <code>MIT</code> - <code>Apache-2.0</code> - <code>GPL-3.0</code> - <code>BSD-3-Clause</code> - <code>MPL-2.0</code></p>"},{"location":"user-guide/adding-exporters/#upstream-configuration","title":"Upstream Configuration","text":"<pre><code>upstream:\n  type: github\n  repo: owner/my_exporter\n  strategy: latest_release\n  # Optional: custom archive naming pattern\n  archive_name: \"{name}-{clean_version}-linux-{arch}.tar.gz\"\n</code></pre>"},{"location":"user-guide/adding-exporters/#build-configuration","title":"Build Configuration","text":"<pre><code>build:\n  method: binary_repack\n  binary_name: my_exporter\n  archs:\n    - amd64\n    - arm64\n  # Optional: additional binaries from the archive\n  extra_binaries: []\n  # Optional: extra files to download\n  extra_sources: []\n</code></pre>"},{"location":"user-guide/adding-exporters/#rpm-artifacts","title":"RPM Artifacts","text":"<pre><code>artifacts:\n  rpm:\n    enabled: true\n    summary: My Service Prometheus Exporter\n    targets: [el8, el9, el10]\n    systemd:\n      enabled: true\n      # Optional: command-line arguments\n      arguments: [\"--config.file=/etc/my_exporter/config.yml\"]\n    # Optional: config files\n    extra_files:\n      - source: assets/config.yml\n        dest: /etc/my_exporter/config.yml\n        mode: \"0640\"\n        config: true\n    # Optional: data directories\n    directories:\n      - path: /var/lib/my_exporter\n        owner: my_exporter\n        group: my_exporter\n    # Optional: system user\n    system_user: my_exporter\n    # Optional: dependencies\n    dependencies: []\n</code></pre>"},{"location":"user-guide/adding-exporters/#docker-artifacts","title":"Docker Artifacts","text":"<pre><code>artifacts:\n  docker:\n    enabled: true\n    base_image: registry.access.redhat.com/ubi9/ubi-minimal:latest\n    entrypoint: [\"/usr/bin/my_exporter\"]\n    cmd: []\n    validation:\n      enabled: true\n      port: 9121\n</code></pre>"},{"location":"user-guide/adding-exporters/#step-3-add-configuration-files-optional","title":"Step 3: Add Configuration Files (Optional)","text":"<p>If your exporter needs configuration files:</p> <ol> <li>Create files in <code>exporters/my_exporter/assets/</code></li> <li>Reference them in the manifest's <code>extra_files</code> section</li> </ol> <p>Example:</p> <pre><code># Create config file\ncat &gt; exporters/my_exporter/assets/config.yml &lt;&lt; 'EOF'\nlisten_address: \":9121\"\nlog_level: info\nEOF\n</code></pre>"},{"location":"user-guide/adding-exporters/#step-4-test-locally","title":"Step 4: Test Locally","text":"<p>Run the comprehensive test using Docker:</p> <pre><code>./devctl test-exporter my_exporter\n</code></pre> <p>Or using Make: <pre><code>make test-exporter EXPORTER=my_exporter\n</code></pre></p> <p>This will:</p> <ul> <li>Generate build artifacts</li> <li>Build RPM for EL9/x86_64</li> <li>Build Docker image</li> <li>Run validation tests</li> </ul> <p>For specific options:</p> <pre><code># Test ARM64 build\n./devctl test-exporter my_exporter --arch arm64\n\n# Test specific EL version\n./devctl test-exporter my_exporter --el10\n\n# Enable smoke tests\n./devctl test-exporter my_exporter --smoke\n</code></pre> <p>Quick artifact generation only: <pre><code>./devctl build-exporter my_exporter\n# Output: build/my_exporter/\n</code></pre></p>"},{"location":"user-guide/adding-exporters/#step-5-create-pull-request","title":"Step 5: Create Pull Request","text":"<p>Once local testing passes:</p> <pre><code># Create feature branch\ngit checkout -b feature/add-my-exporter\n\n# Add files\ngit add exporters/my_exporter/\n\n# Commit using conventional commits\ngit commit -m \"feat(exporters): add my_exporter support\n\n- Add manifest for my_exporter v1.2.3\n- Include default configuration\n- Support amd64 and arm64 architectures\"\n\n# Push branch\ngit push origin feature/add-my-exporter\n</code></pre> <p>Create a Pull Request on GitHub. CI will automatically:</p> <p>\u2705 Validate manifest schema \u2705 Build RPM packages (all distros + archs) \u2705 Build Docker images (multi-arch) \u2705 Run validation tests \u2705 Update catalog</p>"},{"location":"user-guide/adding-exporters/#advanced-custom-templates","title":"Advanced: Custom Templates","text":"<p>For complex packaging needs, you can override the default templates.</p>"},{"location":"user-guide/adding-exporters/#custom-rpm-spec","title":"Custom RPM Spec","text":"<p>Create <code>exporters/my_exporter/templates/my_exporter.spec.j2</code>:</p> <pre><code>%define debug_package %{nil}\n\nName: {{ name }}\nVersion: {{ version }}\n# ... custom spec logic ...\n\n%post\n# Custom post-install logic\nif [ $1 -eq 1 ]; then\n    # First install\n    /usr/bin/my_exporter --init-db\nfi\n</code></pre>"},{"location":"user-guide/adding-exporters/#custom-dockerfile","title":"Custom Dockerfile","text":"<p>Create <code>exporters/my_exporter/templates/Dockerfile.j2</code>:</p> <pre><code>FROM {{ artifacts.docker.base_image }}\n\n# Install dependencies\nRUN microdnf install -y ca-certificates curl &amp;&amp; \\\n    microdnf clean all\n\n# Copy binary\nCOPY {{ build.binary_name }} /usr/bin/{{ name }}\n\n# Custom setup\nRUN /usr/bin/{{ name }} --version\n\nENTRYPOINT {{ artifacts.docker.entrypoint | tojson }}\n</code></pre>"},{"location":"user-guide/adding-exporters/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/adding-exporters/#simple-exporter-no-config","title":"Simple Exporter (No Config)","text":"<p>Minimal manifest with just the binary:</p> <pre><code>artifacts:\n  rpm:\n    enabled: true\n    systemd:\n      enabled: true\n  docker:\n    enabled: true\n    entrypoint: [\"/usr/bin/my_exporter\"]\n</code></pre>"},{"location":"user-guide/adding-exporters/#exporter-with-config-file","title":"Exporter with Config File","text":"<p>Include configuration management:</p> <pre><code>artifacts:\n  rpm:\n    system_user: my_exporter\n    extra_files:\n      - source: assets/config.yml\n        dest: /etc/my_exporter/config.yml\n        mode: \"0640\"\n        config: true\n    systemd:\n      arguments: [\"--config.file=/etc/my_exporter/config.yml\"]\n</code></pre>"},{"location":"user-guide/adding-exporters/#multi-binary-package","title":"Multi-Binary Package","text":"<p>Include helper tools:</p> <pre><code>build:\n  binary_name: main_tool\n  extra_binaries:\n    - helper_tool\n    - cli_tool\n</code></pre>"},{"location":"user-guide/adding-exporters/#troubleshooting","title":"Troubleshooting","text":"<p>See Troubleshooting Guide for common issues.</p>"},{"location":"user-guide/adding-exporters/#next-steps","title":"Next Steps","text":"<ul> <li>Manifest Reference - Complete manifest documentation</li> <li>Local Testing - Advanced testing techniques</li> <li>Contributing Guide - Development best practices</li> </ul>"},{"location":"user-guide/local-testing/","title":"Local Testing","text":"<p>Learn how to test exporters locally before submitting PRs using our Docker-first workflow.</p>"},{"location":"user-guide/local-testing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker - The only requirement!</li> </ul>"},{"location":"user-guide/local-testing/#quick-test-recommended","title":"Quick Test (Recommended)","text":"<p>Test an exporter with full RPM + Docker build + validation:</p> <pre><code>./devctl test-exporter my_exporter\n</code></pre> <p>Or using Make: <pre><code>make test-exporter EXPORTER=my_exporter\n</code></pre></p> <p>This automatically: - \u2705 Validates manifest schema - \u2705 Generates build artifacts - \u2705 Builds RPM for EL9/x86_64 - \u2705 Builds Docker image - \u2705 Runs smoke tests (if configured)</p>"},{"location":"user-guide/local-testing/#advanced-options","title":"Advanced Options","text":""},{"location":"user-guide/local-testing/#test-specific-architecture","title":"Test Specific Architecture","text":"<pre><code>./devctl test-exporter my_exporter --arch arm64\n</code></pre> <p>Supported architectures: <code>amd64</code>, <code>arm64</code></p>"},{"location":"user-guide/local-testing/#test-specific-el-version","title":"Test Specific EL Version","text":"<pre><code>./devctl test-exporter my_exporter --el8   # Enterprise Linux 8\n./devctl test-exporter my_exporter --el9   # Enterprise Linux 9 (default)\n./devctl test-exporter my_exporter --el10  # Enterprise Linux 10\n</code></pre>"},{"location":"user-guide/local-testing/#enable-smoke-tests","title":"Enable Smoke Tests","text":"<pre><code>./devctl test-exporter my_exporter --smoke\n</code></pre> <p>Smoke tests verify: - Container starts successfully - Metrics endpoint responds with HTTP 200 - Binary version command executes</p>"},{"location":"user-guide/local-testing/#build-docker-image-only","title":"Build Docker Image Only","text":"<pre><code>./devctl test-exporter my_exporter --docker\n</code></pre>"},{"location":"user-guide/local-testing/#build-artifacts-only","title":"Build Artifacts Only","text":"<p>If you just need to generate artifacts without building packages:</p> <pre><code>./devctl build-exporter my_exporter\n</code></pre> <p>Output directory: <code>build/my_exporter/</code></p> <p>Generated files: - <code>my_exporter.spec</code> - RPM spec file - <code>Dockerfile</code> - Container build file - Binaries and assets</p>"},{"location":"user-guide/local-testing/#manual-build-steps-advanced","title":"Manual Build Steps (Advanced)","text":"<p>For debugging, you can run each step inside the development container:</p>"},{"location":"user-guide/local-testing/#1-open-development-shell","title":"1. Open Development Shell","text":"<pre><code>./devctl shell\n</code></pre>"},{"location":"user-guide/local-testing/#2-generate-artifacts","title":"2. Generate Artifacts","text":"<pre><code>python3 -m core.engine.builder \\\n  --manifest exporters/my_exporter/manifest.yaml \\\n  --arch amd64 \\\n  --output-dir build/my_exporter\n</code></pre>"},{"location":"user-guide/local-testing/#3-build-rpm","title":"3. Build RPM","text":"<pre><code>./core/scripts/build_rpm.sh \\\n  build/my_exporter/my_exporter.spec \\\n  build/my_exporter/rpms \\\n  amd64 \\\n  almalinux:9\n</code></pre>"},{"location":"user-guide/local-testing/#4-build-docker-image","title":"4. Build Docker Image","text":"<pre><code>docker build -t monitoring-hub/my_exporter:local build/my_exporter\n</code></pre>"},{"location":"user-guide/local-testing/#5-test-container","title":"5. Test Container","text":"<pre><code># Start container\ndocker run -d -p 9100:9100 --name test_exporter \\\n  monitoring-hub/my_exporter:local\n\n# Check metrics\ncurl http://localhost:9100/metrics\n\n# Cleanup\ndocker stop test_exporter &amp;&amp; docker rm test_exporter\n</code></pre>"},{"location":"user-guide/local-testing/#validation-checklist","title":"Validation Checklist","text":"<p>The test script automatically validates:</p> <ul> <li>\u2705 Manifest schema is valid (marshmallow validation)</li> <li>\u2705 Binary downloads successfully from upstream</li> <li>\u2705 Archive extraction works correctly</li> <li>\u2705 RPM spec renders without errors</li> <li>\u2705 RPM builds successfully</li> <li>\u2705 Docker image builds</li> <li>\u2705 Container starts (if smoke tests enabled)</li> <li>\u2705 Metrics endpoint responds (if validation.port configured)</li> <li>\u2705 Version command succeeds (if validation.command configured)</li> </ul>"},{"location":"user-guide/local-testing/#quick-commands-reference","title":"Quick Commands Reference","text":"<pre><code># List all exporters\n./devctl list-exporters\n\n# Build artifacts only\n./devctl build-exporter &lt;name&gt;\n\n# Full test with defaults\n./devctl test-exporter &lt;name&gt;\n\n# Test with all options\n./devctl test-exporter &lt;name&gt; --arch arm64 --el10 --docker --smoke\n\n# Open interactive shell\n./devctl shell\n\n# Run Python command\n./devctl python -m core.engine.builder --help\n</code></pre>"},{"location":"user-guide/local-testing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/local-testing/#image-not-found","title":"Image Not Found","text":"<p>If you see \"Development image not found\", build it first:</p> <pre><code>./devctl build\n</code></pre>"},{"location":"user-guide/local-testing/#permission-denied-on-rpm-build","title":"Permission Denied on RPM Build","text":"<p>Ensure Docker daemon is running and your user has permissions:</p> <pre><code>docker ps\n</code></pre>"},{"location":"user-guide/local-testing/#manifest-validation-errors","title":"Manifest Validation Errors","text":"<p>Check your manifest against the reference:</p> <pre><code># View reference manifest\ncat manifest.reference.yaml\n\n# Validate specific manifest\n./devctl shell\npython3 -m core.engine.schema\n</code></pre> <p>See Troubleshooting Guide for more common issues.</p>"},{"location":"user-guide/local-testing/#next-steps","title":"Next Steps","text":"<ul> <li>Adding Exporters - Complete guide</li> <li>Manifest Reference - Schema documentation</li> <li>Development Guide - Contributing workflow</li> </ul>"},{"location":"user-guide/manifest-reference/","title":"Manifest Reference","text":"<p>Complete reference for the exporter manifest YAML format.</p>"},{"location":"user-guide/manifest-reference/#quick-example","title":"Quick Example","text":"<pre><code>name: my_exporter\ndescription: Exports metrics for My Service\ncategory: Database\nversion: v1.2.3\n\nupstream:\n  type: github\n  repo: owner/my_exporter\n  strategy: latest_release\n\nbuild:\n  method: binary_repack\n  binary_name: my_exporter\n  archs: [amd64, arm64]\n\nartifacts:\n  rpm:\n    enabled: true\n    systemd:\n      enabled: true\n  docker:\n    enabled: true\n    entrypoint: [\"/usr/bin/my_exporter\"]\n    validation:\n      port: 9100\n</code></pre>"},{"location":"user-guide/manifest-reference/#complete-reference","title":"Complete Reference","text":"<p>For the full manifest schema with all available options, see the manifest.reference.yaml file in the repository.</p>"},{"location":"user-guide/manifest-reference/#field-descriptions","title":"Field Descriptions","text":""},{"location":"user-guide/manifest-reference/#identity","title":"Identity","text":"<ul> <li><code>name</code> (required): Technical name (e.g., <code>node_exporter</code>)</li> <li><code>description</code> (required): Short description</li> <li><code>category</code> (required): System, Database, Web, Network, etc.</li> <li><code>version</code> (required): Upstream version (e.g., <code>v1.2.3</code>)</li> </ul>"},{"location":"user-guide/manifest-reference/#upstream","title":"Upstream","text":"<ul> <li><code>type</code>: Always <code>github</code></li> <li><code>repo</code> (required): GitHub repository (e.g., <code>prometheus/node_exporter</code>)</li> <li><code>strategy</code>: <code>latest_release</code> (default) or <code>pinned</code></li> <li><code>archive_name</code>: Custom archive name pattern (optional)</li> </ul>"},{"location":"user-guide/manifest-reference/#build","title":"Build","text":"<ul> <li><code>method</code>: <code>binary_repack</code> or <code>source_build</code></li> <li><code>binary_name</code> (required): Main binary name</li> <li><code>archs</code>: List of architectures (<code>amd64</code>, <code>arm64</code>)</li> <li><code>extra_binaries</code>: Additional binaries to extract</li> <li><code>extra_sources</code>: External files to download</li> </ul>"},{"location":"user-guide/manifest-reference/#artifacts-rpm","title":"Artifacts - RPM","text":"<ul> <li><code>enabled</code>: Enable RPM generation</li> <li><code>summary</code>: Package summary</li> <li><code>targets</code>: EL versions (<code>el8</code>, <code>el9</code>, <code>el10</code>)</li> <li><code>systemd.enabled</code>: Create systemd service</li> <li><code>systemd.arguments</code>: Command-line args</li> <li><code>system_user</code>: Create system user</li> <li><code>extra_files</code>: Config files to include</li> <li><code>directories</code>: Data directories to create</li> <li><code>dependencies</code>: Package dependencies</li> </ul>"},{"location":"user-guide/manifest-reference/#artifacts-docker","title":"Artifacts - Docker","text":"<ul> <li><code>enabled</code>: Enable Docker image</li> <li><code>base_image</code>: Base container image</li> <li><code>entrypoint</code>: Container entrypoint</li> <li><code>cmd</code>: Container command</li> <li><code>validation.enabled</code>: Enable port validation</li> <li><code>validation.port</code>: Port to check</li> </ul> <p>See Adding Exporters for practical examples.</p>"},{"location":"user-guide/troubleshooting/","title":"Troubleshooting","text":"<p>Common issues and solutions when working with Monitoring Hub.</p>"},{"location":"user-guide/troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"user-guide/troubleshooting/#dnf-repository-not-found","title":"DNF Repository Not Found","text":"<p>Problem: <code>Error: Failed to download metadata for repo</code></p> <p>Solution:</p> <pre><code># Clear DNF cache\nsudo dnf clean all\n\n# Reconfigure repo\nsudo dnf config-manager --add-repo https://sckyzo.github.io/monitoring-hub/el9/$(arch)/\n</code></pre>"},{"location":"user-guide/troubleshooting/#gpg-signature-verification-failed","title":"GPG Signature Verification Failed","text":"<p>Problem: Packages fail signature verification</p> <p>Solution: Packages are not signed. Disable GPG check:</p> <pre><code>sudo dnf install --nogpgcheck node_exporter\n</code></pre>"},{"location":"user-guide/troubleshooting/#build-issues","title":"Build Issues","text":""},{"location":"user-guide/troubleshooting/#binary-not-found-in-archive","title":"Binary Not Found in Archive","text":"<p>Problem: <code>Warning: Binary 'my_exporter' not found</code></p> <p>Solution: Check the archive structure and update <code>archive_name</code> pattern:</p> <pre><code># Check actual archive structure\ncurl -L https://github.com/owner/repo/releases/download/v1.0.0/archive.tar.gz | tar -tzf - | head\n</code></pre>"},{"location":"user-guide/troubleshooting/#version-mismatch","title":"Version Mismatch","text":"<p>Problem: Wrong version is downloaded</p> <p>Solution: Update manifest version and ensure it matches upstream tag format (with or without <code>v</code> prefix).</p>"},{"location":"user-guide/troubleshooting/#architecture-not-available","title":"Architecture Not Available","text":"<p>Problem: Build fails for ARM64</p> <p>Solution: Check if upstream provides ARM64 binaries. Update manifest <code>archs</code> if needed.</p>"},{"location":"user-guide/troubleshooting/#runtime-issues","title":"Runtime Issues","text":""},{"location":"user-guide/troubleshooting/#service-wont-start","title":"Service Won't Start","text":"<p>Problem: <code>systemctl start my_exporter</code> fails</p> <p>Solution:</p> <pre><code># Check service status\nsudo systemctl status my_exporter\n\n# Check logs\nsudo journalctl -u my_exporter -n 50\n\n# Test binary manually\nsudo -u my_exporter /usr/bin/my_exporter --help\n</code></pre>"},{"location":"user-guide/troubleshooting/#port-already-in-use","title":"Port Already in Use","text":"<p>Problem: Exporter can't bind to port</p> <p>Solution:</p> <pre><code># Find what's using the port\nsudo lsof -i :9100\n\n# Change port in config or systemd override\nsudo systemctl edit my_exporter\n</code></pre>"},{"location":"user-guide/troubleshooting/#permission-issues","title":"Permission Issues","text":"<p>Problem: Exporter can't read/write files</p> <p>Solution:</p> <pre><code># Check file permissions\nls -la /etc/my_exporter/\nls -la /var/lib/my_exporter/\n\n# Fix ownership\nsudo chown -R my_exporter:my_exporter /var/lib/my_exporter/\n</code></pre>"},{"location":"user-guide/troubleshooting/#docker-issues","title":"Docker Issues","text":""},{"location":"user-guide/troubleshooting/#image-pull-failed","title":"Image Pull Failed","text":"<p>Problem: Can't pull from GHCR</p> <p>Solution:</p> <pre><code># Ensure you're authenticated\ndocker login ghcr.io\n\n# Or use public access (no auth needed for public images)\ndocker pull ghcr.io/sckyzo/monitoring-hub/node_exporter:latest\n</code></pre>"},{"location":"user-guide/troubleshooting/#container-exits-immediately","title":"Container Exits Immediately","text":"<p>Problem: Container starts then stops</p> <p>Solution:</p> <pre><code># Check container logs\ndocker logs my_exporter\n\n# Run interactively for debugging\ndocker run -it --entrypoint /bin/sh ghcr.io/sckyzo/monitoring-hub/my_exporter:latest\n</code></pre>"},{"location":"user-guide/troubleshooting/#development-issues","title":"Development Issues","text":""},{"location":"user-guide/troubleshooting/#tests-failing","title":"Tests Failing","text":"<p>Problem: <code>pytest</code> fails</p> <p>Solution:</p> <pre><code># Ensure PYTHONPATH is set\nexport PYTHONPATH=$(pwd)\n\n# Run with verbose output\npytest -vv\n\n# Run specific test\npytest core/tests/test_builder.py::test_load_valid_manifest\n</code></pre>"},{"location":"user-guide/troubleshooting/#pre-commit-hooks-failing","title":"Pre-commit Hooks Failing","text":"<p>Problem: <code>pre-commit run</code> fails</p> <p>Solution:</p> <pre><code># Update hooks\npre-commit autoupdate\n\n# Run on all files\npre-commit run --all-files\n\n# Skip hooks if needed (not recommended)\ngit commit --no-verify\n</code></pre>"},{"location":"user-guide/troubleshooting/#getting-help","title":"Getting Help","text":"<p>If your issue isn't covered here:</p> <ol> <li>Check GitHub Issues</li> <li>Review GitHub Actions logs</li> <li>Open a new issue with details</li> </ol>"}]}