name: Release and Publish

on:
  push:
    branches: [ main ]
    paths:
      - 'exporters/**'
      - 'core/**'
      - '.github/workflows/**'
  workflow_dispatch:
    inputs:
      force_rebuild:
        description: 'Force rebuild of all exporters'
        required: false
        default: 'false'
        type: boolean

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

# Ensure only one workflow can update gh-pages at a time
concurrency:
  group: gh-pages-deployment
  cancel-in-progress: false

jobs:
  # 1. Smart Discovery (Incremental Build)
  discover:
    runs-on: ubuntu-latest
    outputs:
      exporters: ${{ steps.smart-filter.outputs.exporters }}
      build_needed: ${{ steps.smart-filter.outputs.build_needed }}
    steps:
      - uses: actions/checkout@v6

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'
      - run: pip install -r requirements/base.txt

      - id: smart-filter
        env:
          FORCE_REBUILD: ${{ inputs.force_rebuild }}
          PYTHONPATH: ${{ github.workspace }}
        run: |
          python3 -m core.engine.state_manager

  # 2. Build Docker Images (Parallel per exporter)
  build-docker:
    needs: discover
    if: needs.discover.outputs.build_needed == 'true'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        exporter: ${{ fromJson(needs.discover.outputs.exporters) }}
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v6

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'
      - run: pip install -r requirements/base.txt

      - name: Log in to Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and Push
        run: |
          exporter="${{ matrix.exporter }}"
          echo "Processing $exporter..."

          # Check if docker is enabled and arch is supported in manifest
          is_enabled=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('artifacts', {}).get('docker', {}).get('enabled', False))")
          is_arch_supported=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print('amd64' in m.get('build', {}).get('archs', ['amd64', 'arm64']))")

          if [ "$is_enabled" != "True" ] || [ "$is_arch_supported" != "True" ]; then
            echo "Docker build disabled or architecture not supported for $exporter. Skipping."
            exit 0
          fi

          # Generate build files (FORCE amd64 for Docker)
          export PYTHONPATH=${{ github.workspace }}
          python3 -m core.engine.builder --manifest "exporters/$exporter/manifest.yaml" --output-dir "build/$exporter" --arch amd64

          version=$(grep "version:" "exporters/$exporter/manifest.yaml" | awk '{print $2}' | tr -d '"')

          if [ -f "build/$exporter/Dockerfile" ]; then
             image_id="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/$exporter"
             image_id=$(echo $image_id | tr '[:upper:]' '[:lower:]')

             description=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('description', ''))")

             docker buildx build \
              --file "build/$exporter/Dockerfile" \
              --push \
              --label "org.opencontainers.image.source=${{ github.server_url }}/${{ github.repository }}/tree/main/exporters/$exporter" \
              --label "org.opencontainers.image.documentation=https://sckyzo.github.io/monitoring-hub/" \
              --label "org.opencontainers.image.description=$description" \
              --tag "$image_id:$version" \
              --tag "$image_id:latest" \
              --platform linux/amd64 \
              "build/$exporter"
          fi

      - name: Container Smoke Test
        run: |
          exporter="${{ matrix.exporter }}"
          # Get validation settings
          v_enabled=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('artifacts', {}).get('docker', {}).get('validation', {}).get('enabled', True))")
          v_port=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('artifacts', {}).get('docker', {}).get('validation', {}).get('port', 'None'))")
          v_cmd=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('artifacts', {}).get('docker', {}).get('validation', {}).get('command', 'None'))")
          v_args=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('artifacts', {}).get('docker', {}).get('validation', {}).get('args', 'None'))")

          if [ "$v_enabled" != "True" ]; then
            echo "Smoke test disabled for $exporter."
            exit 0
          fi

          if [ "$v_port" == "None" ] && [ "$v_cmd" == "None" ]; then
            echo "Smoke test skipped (no port or command defined)."
            exit 0
          fi

          image_id="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/$exporter:latest"
          image_id=$(echo $image_id | tr '[:upper:]' '[:lower:]')

          is_enabled=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('artifacts', {}).get('docker', {}).get('enabled', False))")
          is_arch_supported=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print('amd64' in m.get('build', {}).get('archs', ['amd64', 'arm64']))")

          if [ "$is_enabled" != "True" ] || [ "$is_arch_supported" != "True" ]; then
            echo "Docker disabled or architecture not supported, skipping smoke test."
            exit 0
          fi

          # 1. Command-based validation
          if [ "$v_cmd" != "None" ]; then
             echo "üöÄ Validating $image_id with command: $v_cmd"
             if docker run --rm $image_id $v_cmd; then
               echo "‚úÖ Command validation PASSED!"
             else
               echo "‚ùå Command validation FAILED!"
               exit 1
             fi
          fi

          # 2. Port-based validation
          if [ "$v_port" != "None" ]; then
              echo "üöÄ Validating $image_id on port $v_port..."

              run_args=""
              if [ "$v_args" != "None" ]; then
                 run_args="$v_args"
                 echo "   With arguments: $run_args"
              fi

              container_id=$(docker run -d -p 9999:$v_port $image_id $run_args)

              # Retry loop (max 10 seconds)
              success=false
              for i in {1..5}; do
                echo "Attempt $i: Checking metrics at http://localhost:9999/metrics..."
                # Check for 200 OK or any content that looks like Prometheus metrics
                if curl -s --fail http://localhost:9999/metrics | grep -qiE "prometheus|exporter|metrics|alertmanager|# HELP|# TYPE" ; then
                  echo "‚úÖ Port validation PASSED!"
                  success=true
                  break
                fi
                sleep 2
              done

              if [ "$success" = false ]; then
                echo "‚ùå Port validation FAILED!"
                docker logs $container_id
                docker rm -f $container_id
                exit 1
              fi
              docker rm -f $container_id
          fi

  # 3. Build RPMs (Parallel per exporter, architecture AND distribution)
  build-rpm:
    needs: discover
    if: needs.discover.outputs.build_needed == 'true'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        exporter: ${{ fromJson(needs.discover.outputs.exporters) }}
        arch: [amd64, arm64]
        dist: [el8, el9, el10]
    steps:
      - uses: actions/checkout@v6

      - name: Set up QEMU
        if: matrix.arch == 'arm64'
        uses: docker/setup-qemu-action@v3

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'
      - run: pip install -r requirements/base.txt

      - name: Build RPM
        run: |
          exporter="${{ matrix.exporter }}"
          arch="${{ matrix.arch }}"
          dist="${{ matrix.dist }}"

          is_target=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print('$dist' in m.get('artifacts', {}).get('rpm', {}).get('targets', []))")
          is_enabled=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('artifacts', {}).get('rpm', {}).get('enabled', False))")
          is_arch_supported=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print('$arch' in m.get('build', {}).get('archs', ['amd64', 'arm64']))")

          if [ "$is_enabled" != "True" ] || [ "$is_target" != "True" ] || [ "$is_arch_supported" != "True" ]; then
            echo "RPM build, distribution $dist or architecture $arch not requested for $exporter. Skipping."
            exit 0
          fi

          echo "Building RPM for $exporter ($arch) on $dist..."

          case $dist in
            el8) image="almalinux:8" ;;
            el9) image="almalinux:9" ;;
            el10) image="quay.io/centos/centos:stream10" ;;
            *) image="almalinux:9" ;;
          esac

          build_dir="build/$exporter-$arch-$dist"
          export PYTHONPATH=${{ github.workspace }}
          python3 -m core.engine.builder --manifest "exporters/$exporter/manifest.yaml" --output-dir "$build_dir" --arch "$arch"

          spec_file="$build_dir/$exporter.spec"
          if [ -f "$spec_file" ]; then
            chmod +x core/scripts/build_rpm.sh core/scripts/rpm_entrypoint.sh
            ./core/scripts/build_rpm.sh "$spec_file" "$build_dir/rpms" "$arch" "$image"
          fi

      - name: Upload Artifact
        uses: actions/upload-artifact@v6
        with:
          name: rpm-${{ matrix.exporter }}-${{ matrix.arch }}-${{ matrix.dist }}
          path: build/**/rpms/**/*.rpm
          if-no-files-found: ignore
          retention-days: 1

  # 4. Build DEBs (Parallel per exporter, architecture AND distribution)
  build-deb:
    needs: discover
    if: needs.discover.outputs.build_needed == 'true'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        exporter: ${{ fromJson(needs.discover.outputs.exporters) }}
        arch: [amd64, arm64]
        dist: [ubuntu-22.04, ubuntu-24.04, debian-12, debian-13]
    steps:
      - uses: actions/checkout@v6

      - name: Set up QEMU
        if: matrix.arch == 'arm64'
        uses: docker/setup-qemu-action@v3

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'
      - run: pip install -r requirements/base.txt

      - name: Build DEB
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          EXPORTER: ${{ matrix.exporter }}
          ARCH: ${{ matrix.arch }}
          DIST: ${{ matrix.dist }}
        run: |
          is_target=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$EXPORTER/manifest.yaml')); print('$DIST' in m.get('artifacts', {}).get('deb', {}).get('targets', []))")
          is_enabled=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$EXPORTER/manifest.yaml')); print(m.get('artifacts', {}).get('deb', {}).get('enabled', False))")
          is_arch_supported=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$EXPORTER/manifest.yaml')); print('$ARCH' in m.get('build', {}).get('archs', ['amd64', 'arm64']))")

          if [ "$is_enabled" != "True" ] || [ "$is_target" != "True" ] || [ "$is_arch_supported" != "True" ]; then
            echo "DEB build, distribution $DIST or architecture $ARCH not requested for $EXPORTER. Skipping."
            exit 0
          fi

          echo "Building DEB for $EXPORTER ($ARCH) on $DIST..."

          case $DIST in
            ubuntu-22.04) image="ubuntu:22.04" ;;
            ubuntu-24.04) image="ubuntu:24.04" ;;
            debian-12) image="debian:12" ;;
            debian-13) image="debian:trixie" ;;
            *) image="ubuntu:22.04" ;;
          esac

          build_dir="build/$EXPORTER-$ARCH-$DIST"
          export PYTHONPATH=${{ github.workspace }}
          python3 -m core.engine.builder --manifest "exporters/$EXPORTER/manifest.yaml" --output-dir "$build_dir" --arch "$ARCH"

          if [ -d "$build_dir/debian" ]; then
            chmod +x core/scripts/build_deb.sh core/scripts/deb_entrypoint.sh
            mkdir -p "$build_dir/debs"
            ./core/scripts/build_deb.sh "$build_dir" "$build_dir/debs" "$ARCH" "$image"
          else
            echo "No debian/ directory found. DEB disabled for $EXPORTER."
            exit 0
          fi

      - name: Sign DEB
        if: success()
        env:
          GPG_PRIVATE_KEY: ${{ secrets.GPG_PRIVATE_KEY }}
          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}
          GPG_KEY_ID: ${{ secrets.GPG_KEY_ID }}
          EXPORTER: ${{ matrix.exporter }}
          ARCH: ${{ matrix.arch }}
          DIST: ${{ matrix.dist }}
        run: |
          build_dir="build/$EXPORTER-$ARCH-$DIST"

          for deb in "$build_dir"/debs/*.deb; do
            if [ -f "$deb" ]; then
              echo "Signing $deb..."
              chmod +x core/scripts/sign_deb_container.sh
              ./core/scripts/sign_deb_container.sh "$deb" "$GPG_PRIVATE_KEY" "$GPG_PASSPHRASE" "$GPG_KEY_ID" "$DIST"
            fi
          done

      - name: Install and Test DEB
        if: success()
        env:
          EXPORTER: ${{ matrix.exporter }}
          ARCH: ${{ matrix.arch }}
          DIST: ${{ matrix.dist }}
        run: |
          build_dir="build/$EXPORTER-$ARCH-$DIST"

          case $DIST in
            ubuntu-22.04) image="ubuntu:22.04" ;;
            ubuntu-24.04) image="ubuntu:24.04" ;;
            debian-12) image="debian:12" ;;
            debian-13) image="debian:trixie" ;;
            *) image="ubuntu:22.04" ;;
          esac

          deb_file=$(find "$build_dir"/debs -name "*.deb" | head -1)

          if [ -z "$deb_file" ]; then
            echo "No DEB file found, skipping test."
            exit 0
          fi

          echo "Testing installation of $(basename "$deb_file") in $image container..."

          docker run --rm \
            --platform "linux/$ARCH" \
            -v "$(pwd)/$build_dir/debs:/debs:ro" \
            "$image" \
            bash -c "
              apt-get update -qq > /dev/null 2>&1 &&
              apt-get install -y /debs/*.deb &&
              echo 'Installation successful!' &&
              dpkg -L \$(dpkg-deb --field /debs/*.deb Package) | head -10
            "

      - name: Upload Artifact
        uses: actions/upload-artifact@v6
        with:
          name: deb-${{ matrix.exporter }}-${{ matrix.arch }}-${{ matrix.dist }}
          path: build/**/debs/**/*.deb*
          if-no-files-found: ignore
          retention-days: 1

  # 5. Publish YUM Repo & Website (Fan-in)
  publish-yum:
    if: always() && !cancelled() && needs.discover.outputs.build_needed == 'true'
    needs: [build-rpm, build-deb, build-docker]
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v6

      - name: Download All Artifacts
        uses: actions/download-artifact@v7
        with:
          path: all_rpms
          pattern: rpm-*
          merge-multiple: true
        continue-on-error: true

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'
      - run: pip install -r requirements/base.txt

      - name: Update Repository and Site
        run: |
          git fetch origin gh-pages
          git worktree add -B gh-pages gh-pages-dist origin/gh-pages

          cd gh-pages-dist

          for dist in el8 el9 el10; do
            for arch_name in x86_64 aarch64; do
              mkdir -p "$dist/$arch_name"
              echo "Moving RPMs for $dist/$arch_name..."
              find ../all_rpms -name "*.$dist*.$arch_name.rpm" -exec cp -v {} "$dist/$arch_name/" \;

              if [ "$(ls -A $dist/$arch_name/*.rpm 2>/dev/null)" ]; then
                echo "Generating YUM metadata for $dist/$arch_name..."
                docker run --rm -v $(pwd):/repo almalinux:9 /bin/bash -c "dnf install -y createrepo_c && \
                   createrepo_c /repo/$dist/$arch_name && \
                   chown -R $(id -u):$(id -g) /repo"
              fi
            done
          done

          find . -type d -not -path '*/.*' | while read dir;
          do
            echo "Generating index for $dir"
            echo "<!DOCTYPE html><html><head><title>Index of $dir</title><meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"><style>body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif;padding:20px;line-height:1.5}h1{margin-bottom:20px;font-size:1.5em}a{text-decoration:none;color:#0366d6}a:hover{text-decoration:underline}ul{list-style-type:none;padding:0}li{padding:5px 0;border-bottom:1px solid #eee}</style></head><body>" > "$dir/index.html"
            echo "<h1>Index of $dir</h1>" >> "$dir/index.html"
            echo "<ul><li><a href=\"../\">üìÇ Parent Directory</a></li>" >> "$dir/index.html"
            for f in "$dir"/*;
            do
              fname=$(basename "$f")
              if [ "$fname" != "index.html" ]; then
                 if [ -d "$f" ]; then
                   echo "<li><a href=\"$fname/\">üìÅ $fname/</a></li>" >> "$dir/index.html"
                 else
                   size=$(du -h "$f" | cut -f1)
                   echo "<li><a href=\"$fname\">üìÑ $fname</a> <span style=\"color:#666;font-size:0.85em;float:right\">$size</span></li>" >> "$dir/index.html"
                 fi
              fi
            done
            echo "</ul></body></html>" >> "$dir/index.html"
          done

          cd ..
          export PYTHONPATH=${{ github.workspace }}
          python3 -m core.engine.site_generator --output gh-pages-dist/index.html --repo-dir gh-pages-dist

          # Validate generated site
          python3 core/scripts/validate_site.py gh-pages-dist

          cd gh-pages-dist
          git config user.name "Monitoring Hub Bot"
          git config user.email "bot@monitoring-hub.local"
          git add .

          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "chore: update all yum repositories and portal [skip ci]"

            # Push with retry logic for concurrent updates
            MAX_RETRIES=3
            RETRY_COUNT=0
            while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
              if git push origin gh-pages; then
                echo "Successfully pushed to gh-pages"
                exit 0
              else
                RETRY_COUNT=$((RETRY_COUNT + 1))
                if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                  echo "Push failed, pulling latest changes and retrying ($RETRY_COUNT/$MAX_RETRIES)..."
                  git pull --rebase origin gh-pages
                else
                  echo "Failed to push after $MAX_RETRIES attempts"
                  exit 1
                fi
              fi
            done
          fi

  # 6. Publish APT Repository (Fan-in)
  publish-apt:
    if: always() && !cancelled() && needs.discover.outputs.build_needed == 'true'
    needs: [build-deb, build-docker]
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v6

      - name: Download All DEB Artifacts
        uses: actions/download-artifact@v7
        with:
          path: all_debs
          pattern: deb-*
          merge-multiple: true
        continue-on-error: true

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'
      - run: pip install -r requirements/base.txt

      - name: Create APT Repository
        env:
          GPG_PRIVATE_KEY: ${{ secrets.GPG_PRIVATE_KEY }}
          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}
          GPG_KEY_ID: ${{ secrets.GPG_KEY_ID }}
          GPG_PUBLIC_KEY: ${{ secrets.GPG_PUBLIC_KEY }}
        run: |
          git fetch origin gh-pages
          git worktree add -B gh-pages gh-pages-dist origin/gh-pages

          cd gh-pages-dist

          # Create APT repository structure
          mkdir -p apt/pool/main
          mkdir -p apt/dists/{jammy,noble,bookworm,trixie}/main/{binary-amd64,binary-arm64}

          # Copy all DEBs to pool
          echo "Copying DEB packages to pool..."
          find ../all_debs -name "*.deb" -exec cp -v {} apt/pool/main/ \;

          # Export GPG public key for users
          echo "Exporting GPG public key..."
          echo "$GPG_PUBLIC_KEY" | base64 -d > apt/monitoring-hub.asc

          # Install required tools
          docker run --rm \
            -v $(pwd):/repo \
            -e "GPG_PRIVATE_KEY=$GPG_PRIVATE_KEY" \
            -e "GPG_KEY_ID=$GPG_KEY_ID" \
            -e "GPG_PASSPHRASE=$GPG_PASSPHRASE" \
            ubuntu:22.04 \
            bash -c '
              set -e
              apt-get update -qq > /dev/null
              apt-get install -y -qq dpkg-dev apt-utils gnupg > /dev/null

              cd /repo/apt

              # Import GPG key
              export GNUPGHOME=$(mktemp -d)
              echo "$GPG_PRIVATE_KEY" | base64 -d | gpg --batch --import
              FINGERPRINT=$(gpg --list-keys --with-colons "$GPG_KEY_ID" | awk -F: '\''/^fpr:/ {print $10; exit}'\'')
              echo "${FINGERPRINT}:6:" | gpg --import-ownertrust

              # Generate Packages files for each distribution/architecture
              for dist in jammy noble bookworm trixie; do
                for arch in amd64 arm64; do
                  echo "Generating Packages for $dist/$arch..."

                  mkdir -p dists/$dist/main/binary-$arch

                  # Generate Packages file
                  dpkg-scanpackages --arch $arch pool/main /dev/null > dists/$dist/main/binary-$arch/Packages

                  # Generate Packages.gz
                  gzip -9c dists/$dist/main/binary-$arch/Packages > dists/$dist/main/binary-$arch/Packages.gz
                done

                # Generate Release file
                cd dists/$dist
                {
                  echo "Origin: Monitoring Hub"
                  echo "Label: Monitoring Hub"
                  echo "Suite: $dist"
                  echo "Codename: $dist"
                  echo "Version: 1.0"
                  echo "Architectures: amd64 arm64"
                  echo "Components: main"
                  echo "Description: Monitoring Hub Package Repository"
                  echo "Date: $(date -R -u)"
                } > Release

                # Add file checksums
                apt-ftparchive release . >> Release

                # Sign Release file (create InRelease and Release.gpg)
                gpg --batch --yes --digest-algo SHA512 --clearsign -o InRelease Release
                gpg --batch --yes --digest-algo SHA512 -abs -o Release.gpg Release

                cd ../..
              done

              # Cleanup GPG home
              rm -rf "$GNUPGHOME"

              # Fix permissions
              chown -R $(stat -c "%u:%g" /repo) /repo
            '

          cd ..

          # Regenerate portal with APT availability
          export PYTHONPATH=${{ github.workspace }}
          python3 -m core.engine.site_generator --output gh-pages-dist/index.html --repo-dir gh-pages-dist

          cd gh-pages-dist
          git config user.name "Monitoring Hub Bot"
          git config user.email "bot@monitoring-hub.local"
          git add .

          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "chore: update APT repository [skip ci]"

            # Push with retry logic for concurrent updates
            MAX_RETRIES=3
            RETRY_COUNT=0
            while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
              if git push origin gh-pages; then
                echo "Successfully pushed to gh-pages"
                exit 0
              else
                RETRY_COUNT=$((RETRY_COUNT + 1))
                if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                  echo "Push failed, pulling latest changes and retrying ($RETRY_COUNT/$MAX_RETRIES)..."
                  git pull --rebase origin gh-pages
                else
                  echo "Failed to push after $MAX_RETRIES attempts"
                  exit 1
                fi
              fi
            done
          fi
