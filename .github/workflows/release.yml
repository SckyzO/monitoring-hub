name: Release and Publish

on:
  push:
    branches: [ main ]
    paths:
      - 'exporters/**'
      - 'core/**'
      - '.github/workflows/**'
  workflow_dispatch:
    inputs:
      force_rebuild:
        description: 'Force rebuild of all exporters'
        required: false
        default: 'false'
        type: boolean

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

# Ensure only one release job runs at a time to prevent gh-pages conflicts
concurrency:
  group: release-publish
  cancel-in-progress: false

jobs:
  # 1. Smart Discovery (Incremental Build)
  discover:
    runs-on: ubuntu-latest
    outputs:
      exporters: ${{ steps.smart-filter.outputs.exporters }}
      build_needed: ${{ steps.smart-filter.outputs.build_needed }}
    steps:
      - uses: actions/checkout@v6
      
      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'
      - run: pip install -r core/requirements.txt

      - id: smart-filter
        env:
          FORCE_REBUILD: ${{ inputs.force_rebuild }}
          PYTHONPATH: ${{ github.workspace }}
        run: |
          python3 -m core.engine.state_manager

  # 2. Build Docker Images (Parallel per exporter)
  build-docker:
    needs: discover
    if: needs.discover.outputs.build_needed == 'true'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        exporter: ${{ fromJson(needs.discover.outputs.exporters) }}
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v6
      
      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'
      - run: pip install -r core/requirements.txt

      - name: Log in to Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
  
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
  
      - name: Build and Push
        run: |
          exporter="${{ matrix.exporter }}"
          echo "Processing $exporter..."
          
          # Check if docker is enabled and arch is supported in manifest
          is_enabled=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('artifacts', {}).get('docker', {}).get('enabled', False))")
          is_arch_supported=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print('amd64' in m.get('build', {}).get('archs', ['amd64', 'arm64']))")
          
          if [ "$is_enabled" != "True" ] || [ "$is_arch_supported" != "True" ]; then
            echo "Docker build disabled or architecture not supported for $exporter. Skipping."
            exit 0
          fi

          # Generate build files (FORCE amd64 for Docker)
          export PYTHONPATH=${{ github.workspace }}
          python3 -m core.engine.builder --manifest "exporters/$exporter/manifest.yaml" --output-dir "build/$exporter" --arch amd64
          
          version=$(grep "version:" "exporters/$exporter/manifest.yaml" | awk '{print $2}' | tr -d '"')
          
          if [ -f "build/$exporter/Dockerfile" ]; then
             image_id="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/$exporter"
             image_id=$(echo $image_id | tr '[:upper:]' '[:lower:]')
            
             description=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('description', ''))")
             
             docker buildx build \
              --file "build/$exporter/Dockerfile" \
              --push \
              --label "org.opencontainers.image.source=${{ github.server_url }}/${{ github.repository }}/tree/main/exporters/$exporter" \
              --label "org.opencontainers.image.documentation=https://sckyzo.github.io/monitoring-hub/" \
              --label "org.opencontainers.image.description=$description" \
              --tag "$image_id:$version" \
              --tag "$image_id:latest" \
              --platform linux/amd64 \
              "build/$exporter"
          fi

      - name: Container Smoke Test
        run: |
          exporter="${{ matrix.exporter }}"
          # Get validation settings
          v_enabled=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('artifacts', {}).get('docker', {}).get('validation', {}).get('enabled', True))")
          v_port=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('artifacts', {}).get('docker', {}).get('validation', {}).get('port', 'None'))")
          v_cmd=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('artifacts', {}).get('docker', {}).get('validation', {}).get('command', 'None'))")
          v_args=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('artifacts', {}).get('docker', {}).get('validation', {}).get('args', 'None'))")
          
          if [ "$v_enabled" != "True" ]; then
            echo "Smoke test disabled for $exporter."
            exit 0
          fi

          if [ "$v_port" == "None" ] && [ "$v_cmd" == "None" ]; then
            echo "Smoke test skipped (no port or command defined)."
            exit 0
          fi

          image_id="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/$exporter:latest"
          image_id=$(echo $image_id | tr '[:upper:]' '[:lower:]')
          
          is_enabled=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('artifacts', {}).get('docker', {}).get('enabled', False))")
          is_arch_supported=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print('amd64' in m.get('build', {}).get('archs', ['amd64', 'arm64']))")
          
          if [ "$is_enabled" != "True" ] || [ "$is_arch_supported" != "True" ]; then
            echo "Docker disabled or architecture not supported, skipping smoke test."
            exit 0
          fi

          # 1. Command-based validation
          if [ "$v_cmd" != "None" ]; then
             echo "üöÄ Validating $image_id with command: $v_cmd"
             if docker run --rm $image_id $v_cmd; then
               echo "‚úÖ Command validation PASSED!"
             else
               echo "‚ùå Command validation FAILED!"
               exit 1
             fi
          fi

          # 2. Port-based validation
          if [ "$v_port" != "None" ]; then
              echo "üöÄ Validating $image_id on port $v_port..."
              
              run_args=""
              if [ "$v_args" != "None" ]; then
                 run_args="$v_args"
                 echo "   With arguments: $run_args"
              fi

              container_id=$(docker run -d -p 9999:$v_port $image_id $run_args)
              
              # Retry loop (max 10 seconds)
              success=false
              for i in {1..5}; do
                echo "Attempt $i: Checking metrics at http://localhost:9999/metrics..."
                # Check for 200 OK or any content that looks like Prometheus metrics
                if curl -s --fail http://localhost:9999/metrics | grep -qiE "prometheus|exporter|metrics|alertmanager|# HELP|# TYPE" ; then
                  echo "‚úÖ Port validation PASSED!"
                  success=true
                  break
                fi
                sleep 2
              done
              
              if [ "$success" = false ]; then
                echo "‚ùå Port validation FAILED!"
                docker logs $container_id
                docker rm -f $container_id
                exit 1
              fi
              docker rm -f $container_id
          fi

  # 3. Build RPMs (Parallel per exporter, architecture AND distribution)
  build-rpm:
    needs: discover
    if: needs.discover.outputs.build_needed == 'true'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        exporter: ${{ fromJson(needs.discover.outputs.exporters) }}
        arch: [amd64, arm64]
        dist: [el8, el9, el10]
    steps:
      - uses: actions/checkout@v6
      
      - name: Set up QEMU
        if: matrix.arch == 'arm64'
        uses: docker/setup-qemu-action@v3

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'
      - run: pip install -r core/requirements.txt

      - name: Build RPM
        run: |
          exporter="${{ matrix.exporter }}"
          arch="${{ matrix.arch }}"
          dist="${{ matrix.dist }}"
          
          is_target=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print('$dist' in m.get('artifacts', {}).get('rpm', {}).get('targets', []))")
          is_enabled=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(m.get('artifacts', {}).get('rpm', {}).get('enabled', False))")
          is_arch_supported=$(python3 -c "import yaml; m=yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print('$arch' in m.get('build', {}).get('archs', ['amd64', 'arm64']))")
          
          if [ "$is_enabled" != "True" ] || [ "$is_target" != "True" ] || [ "$is_arch_supported" != "True" ]; then
            echo "RPM build, distribution $dist or architecture $arch not requested for $exporter. Skipping."
            exit 0
          fi

          echo "Building RPM for $exporter ($arch) on $dist..."
          
          case $dist in
            el8) image="almalinux:8" ;;
            el9) image="almalinux:9" ;;
            el10) image="quay.io/centos/centos:stream10" ;;
            *) image="almalinux:9" ;;
          esac

          build_dir="build/$exporter-$arch-$dist"
          export PYTHONPATH=${{ github.workspace }}
          python3 -m core.engine.builder --manifest "exporters/$exporter/manifest.yaml" --output-dir "$build_dir" --arch "$arch"
          
          spec_file="$build_dir/$exporter.spec"
          if [ -f "$spec_file" ]; then
            chmod +x core/scripts/build_rpm.sh core/scripts/rpm_entrypoint.sh
            ./core/scripts/build_rpm.sh "$spec_file" "$build_dir/rpms" "$arch" "$image"
          fi

      - name: Upload Artifact
        uses: actions/upload-artifact@v6
        with:
          name: rpm-${{ matrix.exporter }}-${{ matrix.arch }}-${{ matrix.dist }}
          path: build/**/rpms/**/*.rpm
          if-no-files-found: ignore
          retention-days: 1

  # 4. Publish YUM Repo & Website (Fan-in)
  publish-yum:
    if: always() && !cancelled() && needs.discover.outputs.build_needed == 'true'
    needs: [build-rpm, build-docker]
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v6

      - name: Download All Artifacts
        uses: actions/download-artifact@v7
        with:
          path: all_rpms
          pattern: rpm-*
          merge-multiple: true
        continue-on-error: true

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'
      - run: pip install -r core/requirements.txt

      - name: Update Repository and Site
        run: |
          git fetch origin gh-pages
          git worktree add -B gh-pages gh-pages-dist origin/gh-pages
          
          cd gh-pages-dist
          
          for dist in el8 el9 el10; do
            for arch_name in x86_64 aarch64; do
              mkdir -p "$dist/$arch_name"
              echo "Moving RPMs for $dist/$arch_name..."
              find ../all_rpms -name "*.$dist*.$arch_name.rpm" -exec cp -v {} "$dist/$arch_name/" \;
              
              if [ "$(ls -A $dist/$arch_name/*.rpm 2>/dev/null)" ]; then
                echo "Generating YUM metadata for $dist/$arch_name..."
                docker run --rm -v $(pwd):/repo almalinux:9 /bin/bash -c "dnf install -y createrepo_c && \
                   createrepo_c /repo/$dist/$arch_name && \
                   chown -R $(id -u):$(id -g) /repo"
              fi
            done
          done

          find . -type d -not -path '*/.*' | while read dir;
          do
            echo "Generating index for $dir"
            echo "<!DOCTYPE html><html><head><title>Index of $dir</title><meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"><style>body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif;padding:20px;line-height:1.5}h1{margin-bottom:20px;font-size:1.5em}a{text-decoration:none;color:#0366d6}a:hover{text-decoration:underline}ul{list-style-type:none;padding:0}li{padding:5px 0;border-bottom:1px solid #eee}</style></head><body>" > "$dir/index.html"
            echo "<h1>Index of $dir</h1>" >> "$dir/index.html"
            echo "<ul><li><a href=\"../\">üìÇ Parent Directory</a></li>" >> "$dir/index.html"
            for f in "$dir"/*;
            do
              fname=$(basename "$f")
              if [ "$fname" != "index.html" ]; then
                 if [ -d "$f" ]; then
                   echo "<li><a href=\"$fname/\">üìÅ $fname/</a></li>" >> "$dir/index.html"
                 else
                   size=$(du -h "$f" | cut -f1)
                   echo "<li><a href=\"$fname\">üìÑ $fname</a> <span style=\"color:#666;font-size:0.85em;float:right\">$size</span></li>" >> "$dir/index.html"
                 fi
              fi
            done
            echo "</ul></body></html>" >> "$dir/index.html"
          done

          cd ..
          export PYTHONPATH=${{ github.workspace }}
          python3 -m core.engine.site_generator --output gh-pages-dist/index.html --repo-dir gh-pages-dist
          
          # Validate generated site
          python3 core/scripts/validate_site.py gh-pages-dist
          
          cd gh-pages-dist
          git config user.name "Monitoring Hub Bot"
          git config user.email "bot@monitoring-hub.local"
          git add .
          
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "chore: update all yum repositories and portal [skip ci]"
            # Pull latest changes to avoid conflicts
            git pull --rebase origin gh-pages
            git push origin gh-pages
          fi
