name: ğŸš€ Release
run-name: ğŸš€ Release - ${{ inputs.exporter }}

on:
  workflow_dispatch:
    inputs:
      exporter:
        description: 'Exporter to build'
        required: true
        default: 'node_exporter'
        type: string
      arch:
        description: 'Architecture filter (default: all)'
        required: false
        type: choice
        options:
          - all
          - amd64
          - arm64
        default: 'all'
      dist:
        description: 'Distribution filter (default: all)'
        required: false
        type: choice
        options:
          - all
          - el8
          - el9
          - el10
          - ubuntu-22.04
          - ubuntu-24.04
          - debian-12
          - debian-13
        default: 'all'
      package_type:
        description: 'Package type filter (default: all)'
        required: false
        type: choice
        options:
          - all
          - rpm
          - deb
          - docker
        default: 'all'

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

# Ensure only one release per exporter at a time (allow parallel builds for different exporters)
concurrency:
  group: release-${{ inputs.exporter }}
  cancel-in-progress: false

jobs:
  # Get version once and reuse across all jobs
  get-version:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      version: ${{ steps.version.outputs.version }}
    steps:
      - uses: actions/checkout@v6

      - name: ğŸ“‹ Extract Version
        id: version
        run: |
          exporter="${{ inputs.exporter }}"
          version=$(python3 -c "import yaml, sys; manifest = yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(manifest['version'].lstrip('v'))")
          echo "version=$version" >> $GITHUB_OUTPUT
          echo "ğŸ“Œ Version: v$version"

  # 1. Build RPM and upload to GitHub Releases
  build-rpm:
    name: RPM - ${{ inputs.exporter }} (${{ matrix.dist }}/${{ matrix.arch }})
    runs-on: ubuntu-latest
    timeout-minutes: 60
    needs: get-version
    if: inputs.package_type == 'all' || inputs.package_type == 'rpm'
    permissions:
      contents: write  # Required for creating releases
    strategy:
      fail-fast: false
      matrix:
        arch: [amd64, arm64]
        dist: [el8, el9, el10]
    steps:
      - uses: actions/checkout@v6

      - name: Check if architecture is supported
        id: check-arch
        run: |
          exporter="${{ inputs.exporter }}"
          arch="${{ matrix.arch }}"
          supported_archs=$(python3 -c "import yaml; manifest = yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(' '.join(manifest.get('build', {}).get('archs', ['amd64', 'arm64'])))")
          echo "Supported archs for $exporter: $supported_archs"
          if echo "$supported_archs" | grep -qw "$arch"; then
            echo "supported=true" >> $GITHUB_OUTPUT
            echo "âœ“ Architecture $arch is supported"
          else
            echo "supported=false" >> $GITHUB_OUTPUT
            echo "âŠ˜ Architecture $arch not supported, skipping"
          fi

      - name: Set up QEMU
        if: steps.check-arch.outputs.supported == 'true' && (inputs.arch == 'all' || inputs.arch == matrix.arch) && (inputs.dist == 'all' || inputs.dist == matrix.dist)
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        if: steps.check-arch.outputs.supported == 'true'
        uses: docker/setup-buildx-action@v3

      - name: Set up Python
        if: steps.check-arch.outputs.supported == 'true'
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'
          cache: 'pip'
          cache-dependency-path: 'requirements/base.txt'

      - run: pip install -r requirements/base.txt
        if: steps.check-arch.outputs.supported == 'true'

      - name: ğŸ”¨ Build RPM
        if: steps.check-arch.outputs.supported == 'true' && (inputs.arch == 'all' || inputs.arch == matrix.arch) && (inputs.dist == 'all' || inputs.dist == matrix.dist)
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          exporter="${{ inputs.exporter }}"
          arch="${{ matrix.arch }}"
          dist="${{ matrix.dist }}"

          echo "::group::ğŸ”¨ Building RPM Package"
          echo "ğŸ“¦ Package: $exporter"
          echo "ğŸ—ï¸  Architecture: $arch"
          echo "ğŸ§ Distribution: $dist"
          echo "::endgroup::"

          case $dist in
            el8) image="almalinux:8" ;;
            el9) image="almalinux:9" ;;
            el10) image="quay.io/centos/centos:stream10" ;;
          esac

          build_dir="build/$exporter-$arch-$dist"

          echo "::group::ğŸ”§ Generating RPM spec file"
          python3 -m core.engine.builder \
            --manifest "exporters/$exporter/manifest.yaml" \
            --output-dir "$build_dir" \
            --arch "$arch"
          echo "âœ“ Spec file generated"
          echo "::endgroup::"

          spec_file="$build_dir/$exporter.spec"
          if [ -f "$spec_file" ]; then
            echo "::group::ğŸ³ Building RPM in container ($image)"
            chmod +x core/scripts/build_rpm.sh core/scripts/rpm_entrypoint.sh
            ./core/scripts/build_rpm.sh "$spec_file" "$build_dir/rpms" "$arch" "$image"
            echo "âœ“ RPM build completed"
            echo "::endgroup::"
          fi

      - name: ğŸ” Sign RPM
        env:
          GPG_PRIVATE_KEY: ${{ secrets.GPG_PRIVATE_KEY }}
          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}
          GPG_KEY_ID: ${{ secrets.GPG_KEY_ID }}
        run: |
          exporter="${{ inputs.exporter }}"
          arch="${{ matrix.arch }}"
          dist="${{ matrix.dist }}"

          build_dir="build/$exporter-$arch-$dist"
          rpm_file=$(find "$build_dir/rpms" -name "*.rpm" | head -1)

          if [ -z "$rpm_file" ]; then
            echo "âš ï¸  No RPM file found, skipping signing"
            exit 0
          fi

          echo "::group::ğŸ” Signing RPM with GPG"
          echo "ğŸ“„ File: $(basename "$rpm_file")"
          chmod +x core/scripts/sign_rpm_container.sh
          ./core/scripts/sign_rpm_container.sh "$rpm_file" "$GPG_PRIVATE_KEY" "$GPG_PASSPHRASE" "$GPG_KEY_ID"
          echo "âœ“ RPM signed successfully"
          echo "::endgroup::"

      - name: â¬†ï¸  Upload to GitHub Releases
        env:
          GITHUB_TOKEN: ${{ github.token }}
        run: |
          exporter="${{ inputs.exporter }}"
          arch="${{ matrix.arch }}"
          dist="${{ matrix.dist }}"
          version="${{ needs.get-version.outputs.version }}"
          build_dir="build/$exporter-$arch-$dist"

          rpm_files=$(find "$build_dir/rpms" -name "*.rpm")
          if [ -z "$rpm_files" ]; then
            echo "âš ï¸  No RPM files to upload"
            exit 0
          fi

          echo "::group::â¬†ï¸  Uploading to GitHub Releases"
          echo "ğŸ·ï¸  Release: v$version"
          echo "ğŸ“¦ Files:"
          for file in $rpm_files; do
            echo "  â†’ $(basename "$file")"
          done

          python3 core/scripts/upload_to_release.py \
            --repo ${{ github.repository }} \
            --exporter "$exporter" \
            --version "$version" \
            --files $rpm_files \
            --output "$build_dir/release_urls.json"

          echo "âœ“ Upload completed"
          echo "::endgroup::"

      - name: ğŸ“… Create Build Info
        run: |
          exporter="${{ inputs.exporter }}"
          version="${{ needs.get-version.outputs.version }}"
          build_dir="build/$exporter-${{ matrix.arch }}-${{ matrix.dist }}"

          # Create build info with timestamp
          cat > "$build_dir/build-info.json" <<EOF
          {
            "exporter": "$exporter",
            "version": "$version",
            "arch": "${{ matrix.arch }}",
            "dist": "${{ matrix.dist }}",
            "build_date": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
            "artifact_type": "rpm"
          }
          EOF

      - name: Upload Release URLs Artifact
        uses: actions/upload-artifact@v6
        with:
          name: release-urls-rpm-${{ inputs.exporter }}-${{ matrix.arch }}-${{ matrix.dist }}
          path: build/**/release_urls.json
          if-no-files-found: ignore
          retention-days: 7

      - name: Upload Build Info Artifact
        uses: actions/upload-artifact@v6
        with:
          name: build-info-rpm-${{ inputs.exporter }}-${{ matrix.arch }}-${{ matrix.dist }}
          path: build/**/build-info.json
          if-no-files-found: ignore
          retention-days: 7

  # 2. Build DEB and upload to GitHub Releases
  build-deb:
    name: DEB - ${{ inputs.exporter }} (${{ matrix.dist }}/${{ matrix.arch }})
    runs-on: ubuntu-latest
    timeout-minutes: 60
    needs: get-version
    if: inputs.package_type == 'all' || inputs.package_type == 'deb'
    permissions:
      contents: write  # Required for creating releases
    strategy:
      fail-fast: false
      matrix:
        arch: [amd64, arm64]
        dist: [ubuntu-22.04, ubuntu-24.04, debian-12, debian-13]
    steps:
      - uses: actions/checkout@v6

      - name: Check if architecture is supported
        id: check-arch
        run: |
          exporter="${{ inputs.exporter }}"
          arch="${{ matrix.arch }}"
          supported_archs=$(python3 -c "import yaml; manifest = yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(' '.join(manifest.get('build', {}).get('archs', ['amd64', 'arm64'])))")
          echo "Supported archs for $exporter: $supported_archs"
          if echo "$supported_archs" | grep -qw "$arch"; then
            echo "supported=true" >> $GITHUB_OUTPUT
            echo "âœ“ Architecture $arch is supported"
          else
            echo "supported=false" >> $GITHUB_OUTPUT
            echo "âŠ˜ Architecture $arch not supported, skipping"
          fi

      - name: Set up QEMU
        if: steps.check-arch.outputs.supported == 'true' && (inputs.arch == 'all' || inputs.arch == matrix.arch) && (inputs.dist == 'all' || inputs.dist == matrix.dist)
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        if: steps.check-arch.outputs.supported == 'true'
        uses: docker/setup-buildx-action@v3

      - name: Set up Python
        if: steps.check-arch.outputs.supported == 'true'
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'
          cache: 'pip'
          cache-dependency-path: 'requirements/base.txt'

      - run: pip install -r requirements/base.txt
        if: steps.check-arch.outputs.supported == 'true'

      - name: ğŸ”¨ Build DEB
        if: steps.check-arch.outputs.supported == 'true' && (inputs.arch == 'all' || inputs.arch == matrix.arch) && (inputs.dist == 'all' || inputs.dist == matrix.dist)
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          exporter="${{ inputs.exporter }}"
          arch="${{ matrix.arch }}"
          dist="${{ matrix.dist }}"

          echo "::group::ğŸ”¨ Building DEB Package"
          echo "ğŸ“¦ Package: $exporter"
          echo "ğŸ—ï¸  Architecture: $arch"
          echo "ğŸ§ Distribution: $dist"
          echo "::endgroup::"

          case $dist in
            ubuntu-22.04) image="ubuntu:22.04" ;;
            ubuntu-24.04) image="ubuntu:24.04" ;;
            debian-12) image="debian:12" ;;
            debian-13) image="debian:trixie" ;;
          esac

          build_dir="build/$exporter-$arch-$dist"

          echo "::group::ğŸ”§ Generating DEB control files"
          python3 -m core.engine.builder \
            --manifest "exporters/$exporter/manifest.yaml" \
            --output-dir "$build_dir" \
            --arch "$arch"
          echo "âœ“ Control files generated"
          echo "::endgroup::"

          echo "::group::ğŸ³ Building DEB in container ($image)"
          chmod +x core/scripts/build_deb.sh core/scripts/deb_entrypoint.sh
          ./core/scripts/build_deb.sh "$build_dir" "$build_dir/debs" "$arch" "$image"
          echo "âœ“ DEB build completed"
          echo "::endgroup::"

      - name: ğŸ” Sign DEB
        env:
          GPG_PRIVATE_KEY: ${{ secrets.GPG_PRIVATE_KEY }}
          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}
          GPG_KEY_ID: ${{ secrets.GPG_KEY_ID }}
        run: |
          exporter="${{ inputs.exporter }}"
          arch="${{ matrix.arch }}"
          dist="${{ matrix.dist }}"

          build_dir="build/$exporter-$dist-$arch"
          deb_file=$(find "$build_dir/debs" -name "*.deb" | head -1)

          if [ -z "$deb_file" ]; then
            echo "âš ï¸  No DEB file found, skipping signing"
            exit 0
          fi

          echo "::group::ğŸ” Signing DEB with GPG"
          echo "ğŸ“„ File: $(basename "$deb_file")"
          chmod +x core/scripts/sign_deb_container.sh
          ./core/scripts/sign_deb_container.sh "$deb_file" "$GPG_PRIVATE_KEY" "$GPG_PASSPHRASE" "$GPG_KEY_ID" "$dist"
          echo "âœ“ DEB signed successfully"
          echo "::endgroup::"

      - name: â¬†ï¸  Upload to GitHub Releases
        env:
          GITHUB_TOKEN: ${{ github.token }}
        run: |
          exporter="${{ inputs.exporter }}"
          arch="${{ matrix.arch }}"
          dist="${{ matrix.dist }}"
          version="${{ needs.get-version.outputs.version }}"
          build_dir="build/$exporter-$arch-$dist"

          deb_files=$(find "$build_dir/debs" -name "*.deb")
          if [ -z "$deb_files" ]; then
            echo "âš ï¸  No DEB files to upload"
            exit 0
          fi

          echo "::group::â¬†ï¸  Uploading to GitHub Releases"
          echo "ğŸ·ï¸  Release: v$version"
          echo "ğŸ“¦ Files:"
          for file in $deb_files; do
            echo "  â†’ $(basename "$file")"
          done

          python3 core/scripts/upload_to_release.py \
            --repo ${{ github.repository }} \
            --exporter "$exporter" \
            --version "$version" \
            --files $deb_files \
            --output "$build_dir/release_urls.json"

          echo "âœ“ Upload completed"
          echo "::endgroup::"

      - name: ğŸ“… Create Build Info
        run: |
          exporter="${{ inputs.exporter }}"
          version="${{ needs.get-version.outputs.version }}"
          build_dir="build/$exporter-${{ matrix.arch }}-${{ matrix.dist }}"

          # Create build info with timestamp
          cat > "$build_dir/build-info.json" <<EOF
          {
            "exporter": "$exporter",
            "version": "$version",
            "arch": "${{ matrix.arch }}",
            "dist": "${{ matrix.dist }}",
            "build_date": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
            "artifact_type": "deb"
          }
          EOF

      - name: Upload Release URLs Artifact
        uses: actions/upload-artifact@v6
        with:
          name: release-urls-deb-${{ inputs.exporter }}-${{ matrix.arch }}-${{ matrix.dist }}
          path: build/**/release_urls.json
          if-no-files-found: ignore
          retention-days: 7

      - name: Upload Build Info Artifact
        uses: actions/upload-artifact@v6
        with:
          name: build-info-deb-${{ inputs.exporter }}-${{ matrix.arch }}-${{ matrix.dist }}
          path: build/**/build-info.json
          if-no-files-found: ignore
          retention-days: 7

  # 3. Build Docker Image
  build-docker:
    name: Docker - ${{ inputs.exporter }}
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: get-version
    if: inputs.package_type == 'all' || inputs.package_type == 'docker'
    permissions:
      contents: read
      packages: write
      security-events: write
    steps:
      - uses: actions/checkout@v6

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'
          cache: 'pip'
          cache-dependency-path: 'requirements/base.txt'
      - run: pip install -r requirements/base.txt

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: ğŸ³ Build and Push Docker Image
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          exporter="${{ inputs.exporter }}"
          version="${{ needs.get-version.outputs.version }}"

          echo "::group::ğŸ” Checking Docker configuration"
          is_enabled=$(python3 -c "import yaml; manifest = yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(manifest.get('artifacts', {}).get('docker', {}).get('enabled', False))")

          if [ "$is_enabled" != "True" ]; then
            echo "Docker build disabled for $exporter. Skipping."
            exit 0
          fi
          echo "âœ“ Docker build enabled"
          echo "::endgroup::"

          echo "::group::ğŸ”§ Generating Dockerfile"
          python3 -m core.engine.builder \
            --manifest "exporters/$exporter/manifest.yaml" \
            --output-dir "build/$exporter" \
            --arch amd64
          echo "âœ“ Dockerfile generated"
          echo "::endgroup::"

          if [ ! -f "build/$exporter/Dockerfile" ]; then
            echo "Error: Dockerfile not found"
            exit 1
          fi

          echo "::group::ğŸ³ Building test image for security scan"
          image_id="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/$exporter"
          image_id=$(echo $image_id | tr '[:upper:]' '[:lower:]')

          # Build amd64 image locally for Trivy scan
          docker buildx build \
            --file "build/$exporter/Dockerfile" \
            --load \
            --platform linux/amd64 \
            --tag "$image_id:scan-$version" \
            "build/$exporter"
          echo "âœ“ Test image built for scanning"
          echo "::endgroup::"

      - name: ğŸ”’ Run Trivy Security Scan
        env:
          EXPORTER: ${{ inputs.exporter }}
          VERSION: ${{ needs.get-version.outputs.version }}
        run: |
          exporter=$(echo "$EXPORTER" | tr '[:upper:]' '[:lower:]')
          image_ref="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/$exporter:scan-$VERSION"
          image_ref=$(echo "$image_ref" | tr '[:upper:]' '[:lower:]')

          echo "::group::ğŸ”’ Scanning image for vulnerabilities"
          echo "Image: $image_ref"

          docker run --rm \
            -v /var/run/docker.sock:/var/run/docker.sock \
            -v $(pwd):/output \
            aquasec/trivy:latest image \
            --format sarif \
            --output /output/trivy-results.sarif \
            --severity CRITICAL,HIGH \
            "$image_ref"

          echo "âœ“ Security scan completed"
          echo "::endgroup::"

      - name: Upload Trivy Results to GitHub Security
        uses: github/codeql-action/upload-sarif@v4
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'
          category: trivy-container-${{ inputs.exporter }}

      - name: Upload Trivy SARIF Artifact
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: trivy-sarif-${{ inputs.exporter }}
          path: trivy-results.sarif
          retention-days: 7

      - name: ğŸ³ Build and Push Multi-Platform Image
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          exporter="${{ inputs.exporter }}"
          version="${{ needs.get-version.outputs.version }}"

          echo "::group::ğŸ³ Building and pushing multi-platform image"
          image_id="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/$exporter"
          image_id=$(echo $image_id | tr '[:upper:]' '[:lower:]')

          description=$(python3 -c "import yaml; manifest = yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(manifest.get('description', ''))")

          # Read supported architectures from manifest (default to both if not specified)
          supported_archs=$(python3 -c "import yaml; manifest = yaml.safe_load(open('exporters/$exporter/manifest.yaml')); archs = manifest.get('build', {}).get('archs', ['amd64', 'arm64']); print(','.join([f'linux/{arch}' for arch in archs]))")
          echo "Building for platforms: $supported_archs"

          source_url="${{ github.server_url }}/${{ github.repository }}/tree/main/exporters/$exporter"

          docker buildx build \
            --file "build/$exporter/Dockerfile" \
            --push \
            --label "org.opencontainers.image.source=$source_url" \
            --label "org.opencontainers.image.documentation=https://sckyzo.github.io/monitoring-hub/" \
            --label "org.opencontainers.image.description=$description" \
            --label "org.opencontainers.image.version=$version" \
            --tag "$image_id:$version" \
            --tag "$image_id:latest" \
            --platform $supported_archs \
            "build/$exporter"

          echo "âœ“ Image pushed: $image_id:$version"
          echo "::endgroup::"

      - name: ğŸ§ª Container Smoke Test
        run: |
          exporter="${{ inputs.exporter }}"

          echo "::group::ğŸ” Checking validation configuration"
          v_enabled=$(python3 -c "import yaml; manifest = yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(manifest.get('artifacts', {}).get('docker', {}).get('validation', {}).get('enabled', True))")

          if [ "$v_enabled" != "True" ]; then
            echo "Smoke test disabled for $exporter."
            exit 0
          fi

          v_port=$(python3 -c "import yaml; manifest = yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(manifest.get('artifacts', {}).get('docker', {}).get('validation', {}).get('port', 'None'))")
          v_cmd=$(python3 -c "import yaml; manifest = yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(manifest.get('artifacts', {}).get('docker', {}).get('validation', {}).get('command', 'None'))")

          if [ "$v_port" == "None" ] && [ "$v_cmd" == "None" ]; then
            echo "No validation configured. Skipping."
            exit 0
          fi
          echo "::endgroup::"

          image_id="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/$exporter:latest"
          image_id=$(echo $image_id | tr '[:upper:]' '[:lower:]')

          # Command-based validation
          if [ "$v_cmd" != "None" ]; then
            echo "::group::ğŸ§ª Testing with command: $v_cmd"
            docker run --rm "$image_id" $v_cmd
            echo "âœ“ Command test passed"
            echo "::endgroup::"
          fi

          # Port-based validation
          if [ "$v_port" != "None" ]; then
            echo "::group::ğŸ§ª Testing HTTP endpoint on port $v_port"
            v_args=$(python3 -c "import yaml; manifest = yaml.safe_load(open('exporters/$exporter/manifest.yaml')); print(manifest.get('artifacts', {}).get('docker', {}).get('validation', {}).get('args', ''))")

            container_id=$(docker run -d -p "$v_port:$v_port" "$image_id" $v_args)
            sleep 5

            if curl -sf "http://localhost:$v_port/metrics" > /dev/null || \
               curl -sf "http://localhost:$v_port/health" > /dev/null || \
               curl -sf "http://localhost:$v_port/" > /dev/null; then
              echo "âœ“ HTTP endpoint test passed"
            else
              echo "âŒ HTTP endpoint test failed"
              docker logs "$container_id"
              docker stop "$container_id"
              exit 1
            fi

            docker stop "$container_id"
            echo "::endgroup::"
          fi

  # 4. Generate YUM/APT Metadata and Portal (single commit to gh-pages)
  publish-metadata:
    needs: [build-rpm, build-deb, build-docker]
    runs-on: ubuntu-latest
    timeout-minutes: 30
    # Serialize all gh-pages pushes to prevent conflicts
    concurrency:
      group: gh-pages-deploy
      cancel-in-progress: false
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v6

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'
          cache: 'pip'
          cache-dependency-path: 'requirements/base.txt'
      - run: pip install -r requirements/base.txt

      - name: Download Release URLs (RPM + DEB)
        uses: actions/download-artifact@v6
        with:
          pattern: release-urls-*
          path: release-urls/
          merge-multiple: true

      - name: Download Build Info
        uses: actions/download-artifact@v6
        with:
          pattern: build-info-*
          path: build-info/
          merge-multiple: true

      - name: ğŸ“¥ Download Trivy SARIF Results
        uses: actions/download-artifact@v6
        continue-on-error: true
        with:
          pattern: trivy-sarif-*
          path: trivy-results/
          merge-multiple: true

      - name: ğŸ“¥ Checkout gh-pages
        run: |
          echo "::group::ğŸ“¥ Setting up gh-pages worktree"
          git fetch origin gh-pages
          git worktree add -B gh-pages gh-pages-dist origin/gh-pages
          echo "âœ“ gh-pages ready"
          echo "::endgroup::"

      - name: ğŸ“¦ Generate YUM Metadata
        env:
          GPG_PRIVATE_KEY: ${{ secrets.GPG_PRIVATE_KEY }}
          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}
          GPG_KEY_ID: ${{ secrets.GPG_KEY_ID }}
        run: |
          echo "::group::ğŸ§¹ Cleaning previous signatures"
          rm -rf gh-pages-dist/*/*/repodata/*.asc
          echo "âœ“ Cleaned"
          echo "::endgroup::"

          for dist in el8 el9 el10; do
            for arch in x86_64 aarch64; do
              echo "::group::ğŸ“¦ Generating YUM metadata for $dist/$arch"

              python3 core/scripts/generate_yum_metadata.py \
                --release-urls-dir release-urls/ \
                --output-dir gh-pages-dist \
                --dist "$dist" \
                --arch "$arch"

              repomd_file="gh-pages-dist/$dist/$arch/repodata/repomd.xml"
              if [ -f "$repomd_file" ]; then
                echo "ğŸ” Signing repomd.xml..."
                echo "$GPG_PRIVATE_KEY" | base64 -d | gpg --batch --import 2>/dev/null
                gpg --batch --passphrase "$GPG_PASSPHRASE" \
                    --detach-sign --armor "$repomd_file"
                echo "âœ“ Metadata generated and signed for $dist/$arch"
              fi
              echo "::endgroup::"
            done
          done

          if [ -n "${{ secrets.GPG_PUBLIC_KEY }}" ]; then
            echo "ğŸ”‘ Publishing GPG public key..."
            echo "${{ secrets.GPG_PUBLIC_KEY }}" | base64 -d > gh-pages-dist/RPM-GPG-KEY-monitoring-hub
            echo "âœ“ GPG key published"
          fi

      - name: ğŸ“¦ Generate APT Metadata
        env:
          GPG_PRIVATE_KEY: ${{ secrets.GPG_PRIVATE_KEY }}
          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}
          GPG_KEY_ID: ${{ secrets.GPG_KEY_ID }}
        run: |
          echo "::group::ğŸ§¹ Cleaning previous signatures"
          rm -rf gh-pages-dist/apt/dists/*/InRelease gh-pages-dist/apt/dists/*/Release.gpg
          echo "âœ“ Cleaned"
          echo "::endgroup::"

          for dist in ubuntu-22.04 ubuntu-24.04 debian-12 debian-13; do
            for arch in amd64 arm64; do
              echo "::group::ğŸ“¦ Generating APT metadata for $dist/$arch"

              python3 core/scripts/generate_apt_metadata.py \
                --release-urls-dir release-urls/ \
                --output-dir gh-pages-dist/apt \
                --dist "$dist" \
                --arch "$arch"

              echo "âœ“ Metadata generated for $dist/$arch"
              echo "::endgroup::"
            done
          done

          echo "::group::ğŸ” Signing Release files"
          echo "$GPG_PRIVATE_KEY" | base64 -d | gpg --batch --import 2>/dev/null

          for release_file in gh-pages-dist/apt/dists/*/Release; do
            if [ -f "$release_file" ]; then
              codename=$(basename $(dirname "$release_file"))
              echo "  â†’ Signing $codename..."

              if [ -n "$GPG_PASSPHRASE" ]; then
                gpg --batch --passphrase "$GPG_PASSPHRASE" \
                    --clearsign --output "$(dirname "$release_file")/InRelease" "$release_file" 2>/dev/null
                gpg --batch --passphrase "$GPG_PASSPHRASE" \
                    --detach-sign --armor --output "$release_file.gpg" "$release_file" 2>/dev/null
              else
                gpg --batch --clearsign --output "$(dirname "$release_file")/InRelease" "$release_file" 2>/dev/null
                gpg --batch --detach-sign --armor --output "$release_file.gpg" "$release_file" 2>/dev/null
              fi
              echo "    âœ“ Signed"
            fi
          done
          echo "::endgroup::"

          if [ -n "${{ secrets.GPG_PUBLIC_KEY }}" ]; then
            echo "ğŸ”‘ Publishing GPG public key..."
            echo "${{ secrets.GPG_PUBLIC_KEY }}" | base64 -d > gh-pages-dist/apt/monitoring-hub.asc
            echo "âœ“ GPG key published"
          fi

      - name: ğŸ“Š Aggregate Security Statistics
        run: |
          echo "::group::ğŸ“Š Aggregating security statistics"

          # Check if SARIF files exist
          if [ -d "trivy-results" ] && [ "$(ls -A trivy-results/*.sarif 2>/dev/null)" ]; then
            echo "Found Trivy SARIF results, aggregating..."

            python3 core/scripts/aggregate_security_stats.py \
              --sarif-dir trivy-results/ \
              --output gh-pages-dist/security-stats.json

            echo "âœ“ Security stats generated"
          else
            echo "â„¹ï¸  No Trivy results found, skipping security stats"
          fi

          echo "::endgroup::"

      - name: ğŸŒ Generate Portal
        run: |
          echo "::group::ğŸŒ Generating web portal"

          python3 -m core.engine.site_generator \
            --output gh-pages-dist/index.html \
            --repo-dir gh-pages-dist \
            --release-urls-dir release-urls/

          echo "âœ“ Portal generated (index.html + catalog.json)"
          echo "::endgroup::"

      - name: ğŸš€ Deploy to gh-pages
        run: |
          echo "::group::ğŸš€ Deploying to GitHub Pages"
          cd gh-pages-dist
          git config user.name "Monitoring Hub Bot"
          git config user.email "bot@monitoring-hub.local"
          git add .

          if git diff --staged --quiet; then
            echo "â„¹ï¸  No changes to commit"
          else
            echo "ğŸ“ Committing changes..."
            git commit -m "chore: update repository metadata and portal"

            echo "â¬†ï¸  Pushing to gh-pages..."
            git push origin gh-pages

            echo "âœ“ Deployment completed"
          fi
          echo "::endgroup::"
