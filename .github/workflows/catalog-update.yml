name: ðŸ“¦ Catalog Update
run-name: ðŸ“¦ Catalog Update - ${{ github.event.workflow_run.id || inputs.workflow_run_id }}

on:
  workflow_run:
    workflows: ["ðŸš€ Build"]
    types: [completed]
    branches: [main]
  workflow_dispatch:
    inputs:
      workflow_run_id:
        description: 'Build workflow run ID to fetch artifacts from'
        required: true
        type: string

permissions:
  contents: write    # Push to gh-pages
  actions: read      # Download artifacts

concurrency:
  group: catalog-update
  cancel-in-progress: false

jobs:
  update-catalog:
    name: ðŸ“¤ Update Catalog & Portal
    runs-on: ubuntu-latest
    timeout-minutes: 30
    # Only run if build workflow succeeded
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    steps:
      - uses: actions/checkout@v6
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.12'
          cache: 'pip'
          cache-dependency-path: 'requirements/base.txt'

      - name: Install dependencies
        run: pip install -r requirements/base.txt

      - name: ðŸ“¥ Download Build Artifacts
        id: download
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          RUN_ID: ${{ github.event.workflow_run.id || inputs.workflow_run_id }}
        run: |
          echo "::group::ðŸ“¥ Downloading artifacts from build workflow"

          # Create artifacts directory
          mkdir -p artifacts

          # Download all artifacts from the build run
          gh run download "$RUN_ID" --dir artifacts || {
            echo "âŒ Failed to download artifacts from run $RUN_ID"
            exit 1
          }

          # List downloaded artifacts
          echo "Downloaded artifacts:"
          find artifacts -type f -name "*.json" | sort

          # Extract list of exporters from artifact directory names
          exporters=$(find artifacts -type d -mindepth 1 -maxdepth 1 -exec basename {} \; | grep -E "^metadata-" | sed 's/^metadata-\(rpm\|deb\|docker\)-//' | cut -d'-' -f1 | sort -u | jq -R -s -c 'split("\n") | map(select(length > 0))')

          echo "exporters=$exporters" >> $GITHUB_OUTPUT
          echo "Found exporters: $exporters"

          echo "::endgroup::"

      - name: ðŸ”§ Setup gh-pages Worktree
        run: |
          echo "::group::ðŸ”§ Setting up gh-pages worktree"

          git config user.name "Monitoring Hub Bot"
          git config user.email "bot@monitoring-hub.local"

          # Fetch gh-pages
          git fetch origin gh-pages || {
            echo "Creating orphan gh-pages branch..."
            git checkout --orphan gh-pages
            git reset --hard
            git commit --allow-empty -m "chore: initialize gh-pages"
            git push origin gh-pages
            git checkout main
          }

          # Setup worktree
          if [ -d "gh-pages-dist" ]; then
            echo "Removing existing worktree..."
            git worktree remove gh-pages-dist --force || rm -rf gh-pages-dist
          fi

          git worktree add gh-pages-dist gh-pages

          echo "âœ“ gh-pages worktree ready at gh-pages-dist/"
          echo "::endgroup::"

      - name: ðŸ“¦ Publish Metadata to Catalog (Sequential)
        env:
          EXPORTERS: ${{ steps.download.outputs.exporters }}
        run: |
          echo "::group::ðŸ“¦ Publishing metadata sequentially"

          cd gh-pages-dist

          # Process each exporter
          echo "$EXPORTERS" | jq -r '.[]' | while read -r exporter; do
            echo ""
            echo "============================================================"
            echo "Processing: $exporter"
            echo "============================================================"

            # Create catalog directory for this exporter
            mkdir -p "catalog/$exporter"

            # Find and copy all metadata files for this exporter
            copied=0
            for artifact_dir in ../artifacts/metadata-*-${exporter}-*; do
              if [ -d "$artifact_dir" ]; then
                echo "Processing artifact: $(basename "$artifact_dir")"

                # Copy JSON files
                for json_file in "$artifact_dir"/*.json; do
                  if [ -f "$json_file" ]; then
                    filename=$(basename "$json_file")
                    cp "$json_file" "catalog/$exporter/$filename"
                    echo "  âœ“ Copied: $filename"
                    ((copied++))
                  fi
                done
              fi
            done

            # Check Docker metadata
            docker_artifact="../artifacts/metadata-docker-${exporter}"
            if [ -d "$docker_artifact" ]; then
              echo "Processing Docker artifact: $(basename "$docker_artifact")"
              for json_file in "$docker_artifact"/*.json; do
                if [ -f "$json_file" ]; then
                  filename=$(basename "$json_file")
                  cp "$json_file" "catalog/$exporter/$filename"
                  echo "  âœ“ Copied: $filename"
                  ((copied++))
                fi
              done
            fi

            if [ $copied -eq 0 ]; then
              echo "âš ï¸  No metadata files found for $exporter"
              continue
            fi

            echo "âœ“ Copied $copied metadata files for $exporter"

            # Aggregate metadata.json for this exporter
            echo "Aggregating metadata for $exporter..."
            cd ..
            python3 core/scripts/aggregate_catalog_metadata.py \
              --exporter "$exporter" \
              --catalog-dir gh-pages-dist/catalog \
              --manifest-path "exporters/$exporter/manifest.yaml" \
              --output "gh-pages-dist/catalog/$exporter/metadata.json" || {
              echo "âš ï¸  Failed to aggregate metadata for $exporter (non-blocking)"
            }
            cd gh-pages-dist

            # Commit this exporter's changes
            git add "catalog/$exporter/"
            if ! git diff --staged --quiet; then
              git commit -m "feat: update catalog metadata for $exporter [skip ci]"
              echo "âœ“ Committed metadata for $exporter"
            else
              echo "â„¹ï¸  No changes for $exporter"
            fi
          done

          cd ..

          echo "::endgroup::"

      - name: ðŸŒ Regenerate Portal
        run: |
          echo "::group::ðŸŒ Regenerating portal"

          # Generate portal HTML using V3 catalog structure
          python3 -m core.engine.site_generator_v2 \
            --output gh-pages-dist/index.html \
            --repo-dir . \
            --catalog-dir gh-pages-dist/catalog

          echo "âœ“ Portal generated"

          # Generate catalog index and exporter metadata files
          cd gh-pages-dist

          # Copy aggregated metadata to catalog root (for backward compatibility)
          for exporter_dir in catalog/*/; do
            if [ -d "$exporter_dir" ]; then
              exporter=$(basename "$exporter_dir")
              if [ -f "$exporter_dir/metadata.json" ]; then
                cp "$exporter_dir/metadata.json" "catalog/${exporter}.json"
                echo "âœ“ Created catalog/${exporter}.json"
              fi
            fi
          done

          # Commit portal changes
          git add index.html catalog/*.json catalog/index.json
          if ! git diff --staged --quiet; then
            git commit -m "chore(site): refresh portal UI/data [skip ci]"
            echo "âœ“ Committed portal update"
          else
            echo "â„¹ï¸  No portal changes"
          fi

          cd ..

          echo "::endgroup::"

      - name: ðŸš€ Push to gh-pages
        run: |
          echo "::group::ðŸš€ Pushing to gh-pages"

          cd gh-pages-dist

          # Check if there are any commits to push
          if git log origin/gh-pages..HEAD --oneline | grep -q .; then
            echo "Pushing $(git log origin/gh-pages..HEAD --oneline | wc -l) commits..."

            # Push with retry
            MAX_RETRIES=3
            RETRY_COUNT=0
            while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
              if git push origin gh-pages; then
                echo "âœ… Successfully pushed to gh-pages"
                break
              else
                RETRY_COUNT=$((RETRY_COUNT + 1))
                if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                  echo "âš ï¸  Push failed, retrying ($RETRY_COUNT/$MAX_RETRIES)..."
                  git pull --rebase origin gh-pages
                else
                  echo "âŒ Failed to push after $MAX_RETRIES attempts"
                  exit 1
                fi
              fi
            done
          else
            echo "â„¹ï¸  No commits to push"
          fi

          cd ..

          echo "::endgroup::"

      - name: ðŸ“Š Summary
        if: always()
        env:
          EXPORTERS: ${{ steps.download.outputs.exporters }}
        run: |
          echo "## ðŸ“¦ Catalog Update Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Exporters processed:**" >> $GITHUB_STEP_SUMMARY
          echo "$EXPORTERS" | jq -r '.[] | "- " + .' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸŒ Portal: https://sckyzo.github.io/monitoring-hub/" >> $GITHUB_STEP_SUMMARY
